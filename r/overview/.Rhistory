# if(!file.exists(dl))
#   download.file("https://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)
ratings_file <- "ml-10M100K/ratings.dat"
if(!file.exists(ratings_file))
unzip(dl, ratings_file)
movies_file <- "ml-10M100K/movies.dat"
if(!file.exists(movies_file))
unzip(dl, movies_file)
ratings <- as.data.frame(str_split(read_lines(ratings_file), fixed("::"), simplify = TRUE),
stringsAsFactors = FALSE)
setwd("C:/edu/ai/data-science/hardvard-x/9.capstone-project/overview")
# Create edx and final_holdout_test sets
##########################################################
# Create edx and final_holdout_test sets
##########################################################
setwd("C:/edu/ai/data-science/hardvard-x/9.capstone-project/overview")
# Note: this process could take a couple of minutes
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
library(tidyverse)
library(caret)
options(timeout = 120)
# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip
dl <- "ml-10M100K.zip"
# if(!file.exists(dl))
#   download.file("https://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)
ratings_file <- "ml-10M100K/ratings.dat"
if(!file.exists(ratings_file))
unzip(dl, ratings_file)
movies_file <- "ml-10M100K/movies.dat"
if(!file.exists(movies_file))
unzip(dl, movies_file)
ratings <- as.data.frame(str_split(read_lines(ratings_file), fixed("::"), simplify = TRUE),
stringsAsFactors = FALSE)
colnames(ratings) <- c("userId", "movieId", "rating", "timestamp")
ratings <- ratings %>%
mutate(userId = as.integer(userId),
movieId = as.integer(movieId),
rating = as.numeric(rating),
timestamp = as.integer(timestamp))
movies <- as.data.frame(str_split(read_lines(movies_file), fixed("::"), simplify = TRUE),
stringsAsFactors = FALSE)
colnames(movies) <- c("movieId", "title", "genres")
movies <- movies %>%
mutate(movieId = as.integer(movieId))
movielens <- left_join(ratings, movies, by = "movieId")
# Final hold-out test set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding") # if using R 3.6 or later
# set.seed(1) # if using R 3.5 or earlier
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]
# Make sure userId and movieId in final hold-out test set are also in edx set
final_holdout_test <- temp %>%
semi_join(edx, by = "movieId") %>%
semi_join(edx, by = "userId")
# Add rows removed from final hold-out test set back into edx set
removed <- anti_join(temp, final_holdout_test)
edx <- rbind(edx, removed)
rm(dl, ratings, movies, test_index, temp, movielens, removed)
library(caret)
library(lubridate)
## The Netflix Prize Dataset
# https://www.asc.ohio-state.edu/statistics/statgen/joul_aut2009/BigChaos.pdf
#-------------------------------------------------------
np_training_set_cnt <- 100480507
np_probe_set_cnt <- 1408395  # subset of `training_set`
probe_set_ratio <- np_probe_set_cnt/np_training_set_cnt
#> [1] 0.0140166
np_qualifying_set_cnt <- 2817131
quiz_set_ratio <- 0.5
test_set_ratio <- 1 - quiz_set_ratio
np_rmse_accepted_max <- 0.8563
#-------------------------------------------------------
#> The goal of the contest is to predict the qualifying set (size: 2817131 samples)
#> and achieve a RMSE score of at least 0.8563 on the quiz subset,
#> to get qualifed for the Grand Prize.
#####################################################
# Inspired by:
# HarvardX: PH125.8x
# Data Science: Machine Learning
## Section 6.2: Recommendation Systems
# Textbook section:
### 33.7 Recommendation Systems
# https://rafalab.github.io/dsbook/large-datasets.html#recommendation-systems
#-------------------------------------------------------
str(edx)
# 'data.frame':	9000055 obs. of  6 variables:
#   $ userId   : int  1 1 1 1 1 1 1 1 1 1 ...
# $ movieId  : int  122 185 292 316 329 355 356 362 364 370 ...
# $ rating   : num  5 5 5 5 5 5 5 5 5 5 ...
# $ timestamp: int  838985046 838983525 838983421 838983392 838983392 838984474 838983653 838984885 838983707 838984596 ...
# $ title    : chr  "Boomerang (1992)" "Net, The (1995)" "Outbreak (1995)" "Stargate (1994)" ...
# $ genres   : chr  "Comedy|Romance" "Action|Crime|Thriller" "Action|Drama|Sci-Fi|Thriller" "Action|Adventure|Sci-Fi" ...
#str(final_holdout_test)
set.seed(2006)
probe_index <- createDataPartition(y = edx$rating, times = 1,
p = probe_set_ratio, list = FALSE)
probe_set_tmp <- edx[probe_index,]
train_set <- edx[-probe_index,]
head(train_set)
#> Make sure userId and movieId in final hold-out test set
#> are also in `train_set` set
probe_set <- probe_set_tmp |>
semi_join(train_set, by = "movieId") |>
semi_join(train_set, by = "userId")
y <- select(train_set, movieId, userId, rating) |>
pivot_wider(names_from = movieId, values_from = rating)
rnames <- y$userId
y <- as.matrix(y[,-1])
rownames(y) <- rnames
movie_map <- train_set |> select(movieId, title) |>
distinct(movieId, .keep_all = TRUE)
#-------------------------------------------------------
RMSE <- function(true_ratings, predicted_ratings){
sqrt(mean((true_ratings - predicted_ratings)^2))
}
mu <- mean(train_set$rating)
mu
#> [1] 3.512465
naive_rmse <- RMSE(probe_set$rating, mu)
naive_rmse
#> [1] 1.061429
#-------------------------------------------------------
## Modeling movie effects
# Y(i,u) = μ + b(i) + ε(i,u)
movie_avgs <- train_set |>
group_by(movieId) |>
summarize(b_i = mean(rating - mu))
str(movie_avgs)
# tibble [10,673 × 2] (S3: tbl_df/tbl/data.frame)
# $ movieId: int [1:10673] 1 2 3 4 5 6 7 8 9 10 ...
# $ b_i    : num [1:10673] 0.415 -0.307 -0.363 -0.643 -0.443 ...
head(movie_avgs)
# # A tibble: 6 × 2
#   movieId    b_i
#     <int>  <dbl>
# 1       1  0.415
# 2       2 -0.307
# 3       3 -0.363
# 4       4 -0.643
# 5       5 -0.443
# 6       6  0.303
fit_movies <- as.data.frame(movie_avgs) |>
mutate(mu = mu)
str(fit_movies)
# 'data.frame':	10673 obs. of  3 variables:
#   $ movieId: int  1 2 3 4 5 6 7 8 9 10 ...
# $ b_i    : num  0.415 -0.307 -0.363 -0.643 -0.443 ...
# $ mu     : num  3.51 3.51 3.51 3.51 3.51 ...
head(fit_movies)
# movieId        b_i      mu
# 1       1  0.4146616 3.51248
# 2       2 -0.3069827 3.51248
# 3       3 -0.3632103 3.51248
# 4       4 -0.6426216 3.51248
# 5       5 -0.4428068 3.51248
# 6       6  0.3026186 3.51248
preds <- mu + probe_set |>
left_join(movie_avgs, by='movieId') |>
pull(b_i)
str(preds)
head(preds)
head(probe_set$rating)
mean(preds)
#> [1] 3.512969
movie_model_rmse <- RMSE(probe_set$rating, preds)
movie_model_rmse
#> [1] 0.9442118
min_user_rates <- 100
n_bins <- 30
train_set |>
group_by(userId) |>
summarize(b_u = mean(rating)) |>
filter(n()>=min_user_rates) |>
ggplot(aes(b_u)) +
geom_histogram(bins = n_bins, color = "black")
# b(u) = mean(y(i, u) - μ - b_i(i))
user_avgs <- train_set |>
left_join(movie_avgs, by='movieId') |>
group_by(userId) |>
summarize(b_u = mean(rating - mu - b_i))
head(user_avgs)
predicted_ratings <- probe_set |>
left_join(movie_avgs, by='movieId') |>
left_join(user_avgs, by='userId') |>
mutate(pred = mu + b_i + b_u) |>
pull(pred)
head(predicted_ratings)
model_2_rmse <- RMSE(probe_set$rating, predicted_ratings)
model_2_rmse
#> [1] 0.8673005
#-------------------------------------------------------
library(lubridate)
date()
start <- Sys.time()
train_set_dm <- train_set |>
left_join(movie_avgs, by='movieId') |>
left_join(user_avgs, by='userId') |>
mutate(rating_residue = rating - mu - b_i - b_u) |>
mutate(date_time = as_datetime(timestamp)) |>
mutate(date = as_date(date_time)) |>
mutate(days = as.integer(date - min_date)) #|>
head(date_effects)
date_effects <- train_set |>
left_join(movie_avgs, by='movieId') |>
left_join(user_avgs, by='userId') |>
group_by(date) |>
summarize(fsmth_d_iu = mean(rating - mu - b_i - b_u))
library(caret)
library(lubridate)
## The Netflix Prize Dataset
# https://www.asc.ohio-state.edu/statistics/statgen/joul_aut2009/BigChaos.pdf
#-------------------------------------------------------
np_training_set_cnt <- 100480507
np_probe_set_cnt <- 1408395  # subset of `training_set`
probe_set_ratio <- np_probe_set_cnt/np_training_set_cnt
#> [1] 0.0140166
np_qualifying_set_cnt <- 2817131
quiz_set_ratio <- 0.5
test_set_ratio <- 1 - quiz_set_ratio
np_rmse_accepted_max <- 0.8563
#-------------------------------------------------------
#> The goal of the contest is to predict the qualifying set (size: 2817131 samples)
#> and achieve a RMSE score of at least 0.8563 on the quiz subset,
#> to get qualifed for the Grand Prize.
#####################################################
# Inspired by:
# HarvardX: PH125.8x
# Data Science: Machine Learning
## Section 6.2: Recommendation Systems
# Textbook section:
### 33.7 Recommendation Systems
# https://rafalab.github.io/dsbook/large-datasets.html#recommendation-systems
#-------------------------------------------------------
str(edx)
# 'data.frame':	9000055 obs. of  6 variables:
#   $ userId   : int  1 1 1 1 1 1 1 1 1 1 ...
# $ movieId  : int  122 185 292 316 329 355 356 362 364 370 ...
# $ rating   : num  5 5 5 5 5 5 5 5 5 5 ...
# $ timestamp: int  838985046 838983525 838983421 838983392 838983392 838984474 838983653 838984885 838983707 838984596 ...
# $ title    : chr  "Boomerang (1992)" "Net, The (1995)" "Outbreak (1995)" "Stargate (1994)" ...
# $ genres   : chr  "Comedy|Romance" "Action|Crime|Thriller" "Action|Drama|Sci-Fi|Thriller" "Action|Adventure|Sci-Fi" ...
#str(final_holdout_test)
set.seed(2006)
probe_index <- createDataPartition(y = edx$rating, times = 1,
p = probe_set_ratio, list = FALSE)
probe_set_tmp <- edx[probe_index,]
train_set <- edx[-probe_index,]
head(train_set)
#> Make sure userId and movieId in final hold-out test set
#> are also in `train_set` set
probe_set <- probe_set_tmp |>
semi_join(train_set, by = "movieId") |>
semi_join(train_set, by = "userId")
y <- select(train_set, movieId, userId, rating) |>
pivot_wider(names_from = movieId, values_from = rating)
rnames <- y$userId
y <- as.matrix(y[,-1])
rownames(y) <- rnames
movie_map <- train_set |> select(movieId, title) |>
distinct(movieId, .keep_all = TRUE)
#-------------------------------------------------------
RMSE <- function(true_ratings, predicted_ratings){
sqrt(mean((true_ratings - predicted_ratings)^2))
}
mu <- mean(train_set$rating)
mu
#> [1] 3.512465
naive_rmse <- RMSE(probe_set$rating, mu)
naive_rmse
#> [1] 1.061429
#-------------------------------------------------------
## Modeling movie effects
# Y(i,u) = μ + b(i) + ε(i,u)
movie_avgs <- train_set |>
group_by(movieId) |>
summarize(b_i = mean(rating - mu))
str(movie_avgs)
# tibble [10,673 × 2] (S3: tbl_df/tbl/data.frame)
# $ movieId: int [1:10673] 1 2 3 4 5 6 7 8 9 10 ...
# $ b_i    : num [1:10673] 0.415 -0.307 -0.363 -0.643 -0.443 ...
head(movie_avgs)
# # A tibble: 6 × 2
#   movieId    b_i
#     <int>  <dbl>
# 1       1  0.415
# 2       2 -0.307
# 3       3 -0.363
# 4       4 -0.643
# 5       5 -0.443
# 6       6  0.303
fit_movies <- as.data.frame(movie_avgs) |>
mutate(mu = mu)
str(fit_movies)
# 'data.frame':	10673 obs. of  3 variables:
#   $ movieId: int  1 2 3 4 5 6 7 8 9 10 ...
# $ b_i    : num  0.415 -0.307 -0.363 -0.643 -0.443 ...
# $ mu     : num  3.51 3.51 3.51 3.51 3.51 ...
head(fit_movies)
# movieId        b_i      mu
# 1       1  0.4146616 3.51248
# 2       2 -0.3069827 3.51248
# 3       3 -0.3632103 3.51248
# 4       4 -0.6426216 3.51248
# 5       5 -0.4428068 3.51248
# 6       6  0.3026186 3.51248
preds <- mu + probe_set |>
left_join(movie_avgs, by='movieId') |>
pull(b_i)
str(preds)
head(preds)
head(probe_set$rating)
mean(preds)
#> [1] 3.512969
movie_model_rmse <- RMSE(probe_set$rating, preds)
movie_model_rmse
#> [1] 0.9442118
min_user_rates <- 100
n_bins <- 30
train_set |>
group_by(userId) |>
summarize(b_u = mean(rating)) |>
filter(n()>=min_user_rates) |>
ggplot(aes(b_u)) +
geom_histogram(bins = n_bins, color = "black")
# b(u) = mean(y(i, u) - μ - b_i(i))
user_avgs <- train_set |>
left_join(movie_avgs, by='movieId') |>
group_by(userId) |>
summarize(b_u = mean(rating - mu - b_i))
head(user_avgs)
predicted_ratings <- probe_set |>
left_join(movie_avgs, by='movieId') |>
left_join(user_avgs, by='userId') |>
mutate(pred = mu + b_i + b_u) |>
pull(pred)
head(predicted_ratings)
model_2_rmse <- RMSE(probe_set$rating, predicted_ratings)
model_2_rmse
#> [1] 0.8673005
#-------------------------------------------------------
library(lubridate)
min_date <- min(train_set_dm$date)
start_date <- function(){
print(date())
Sys.time()
}
end_date <- function(start){
print(date())
Sys.time() - start
}
date()
start <- start_date()
train_set_dm <- train_set |>
left_join(movie_avgs, by='movieId') |>
left_join(user_avgs, by='userId') |>
mutate(rating_residue = rating - mu - b_i - b_u) |>
mutate(date_time = as_datetime(timestamp)) |>
mutate(date = as_date(date_time))
min_date <- min(train_set_dm$date)
train_set_dm <- train_set_dm |>
mutate(days = as.integer(date - min_date)) #|>
#arrange(date)
head(train_set_dm)
end_date(start)
date()
date()
start <- start_date()
date_global_effect <- train_set_dm |>
group_by(days, date) |>
summarise(de = mean(rating_residue))
end_date(start)
date()
head(date_global_effect)
sum(is.na(date_global_effect$de))
date()
start <- start_date()
fit <- loess(de ~ days, data = date_global_effect)
end_date(start)
date()
sum(is.na(fit$fitted))
str(fit$pars)
str(fit$fitted)
date_smoothed_effect <- as.data.frame(date_global_effect) |>
mutate(de_smoothed = fit$fitted)
head(date_smoothed_effect)
date()
start <- start_date()
date_smoothed_effect |>
ggplot(aes(x = days)) +
geom_point(aes(y = de), size = 3, alpha = .5, color = "grey") +
geom_line(aes(y = de_smoothed), color = "red")
end_date(start)
date()
#----------------------------------------------------------------
fit_loess <- function(spans, dgr){
fits <- sapply(spans, function(span){
fit <- loess(de ~ days, span = span, degree = dgr, data = date_global_effect)
fit$fitted
})
}
predict_de_probe <- function(fits){
model_diu_rmses <- sapply(fits, function(smth){
date_smoothed_effect <- as.data.frame(date_global_effect) |>
mutate(de_smoothed = smth)
#head(date_smoothed_effect)
preds <- probe_set |>
mutate(date = as_date(as_datetime(timestamp))) |>
left_join(movie_avgs, by='movieId') |>
left_join(user_avgs, by='userId') |>
left_join(date_smoothed_effect, by='date') |>
#mutate(diu_smth = d_iu_smth) |>
mutate(pred = mu + b_i + b_u + de_smoothed) |>
pull(pred)
RMSE(preds, probe_set$rating)
})
}
#----------------------------------------------------------------------
# spans <- seq(0.0003, 0.002, 0.00001)
spans <- seq(0.0005, 0.0015, 0.00001)
start <- start_date()
fits <- fit_loess(spans,0)
end_date(start)
dim(fits)
df_fits <- as.data.frame(fits)
#str(df_fits)
start <- start_date()
model_diu_rmses <- predict_de_probe(df_fits)
end_date(start)
model_diu_rmses
plot(model_diu_rmses)
min(model_diu_rmses)
#> [1] 0.8670417
idx <- which.min(model_diu_rmses)
idx
spans[idx]
#---------------------------------------------------------------------------
#spans <- seq(0.0005, 0.002, 0.00001)
spans <- seq(0.001, 0.0014, 0.00001)
start <- start_date()
fits <- fit_loess(spans,1)
end_date(start)
dim(fits)
df_fits <- as.data.frame(fits)
#str(df_fits)
start <- start_date()
model_diu_rmses <- predict_de_probe(df_fits)
end_date(start)
model_diu_rmses
plot(model_diu_rmses)
min(model_diu_rmses)
#> [1] 0.8669269
idx <- which.min(model_diu_rmses)
idx # 9
spans[idx]
#> [1] 0.00108
#------------------------------
#spans <- seq(0.0003, 0.01, 0.00001)
spans <- seq(0.0007, 0.002, 0.00001)
start <- start_date()
fits <- fit_loess(spans,2)
end_date(start)
dim(fits)
df_fits <- as.data.frame(fits)
#str(df_fits)
start <- start_date()
model_diu_rmses <- predict_de_probe(df_fits)
end_date(start)
model_diu_rmses
plot(model_diu_rmses)
min(model_diu_rmses)
#> [1] 0.866997
idx <- which.min(model_diu_rmses)
idx # 82
spans[idx]
#> [1] 0.00151
#------------------------------
best_degree <- 1
best_span <- 0.00108
start <- start_date()
fit <- loess(de ~ days,
degree = best_degree,
span = best_span,
data = date_global_effect)
end_date(start)
sum(is.na(fit$fitted))
str(fit$pars)
str(fit$fitted)
#fit$pars
# fit$fitted
date_smoothed_effect <- as.data.frame(date_global_effect) |>
mutate(de_smoothed = fit$fitted)
head(date_smoothed_effect)
start <- start_date()
date_smoothed_effect |>
ggplot(aes(x = days)) +
geom_point(aes(y = de), size = 3, alpha = .5, color = "grey") +
geom_line(aes(y = de_smoothed), color = "red")
end_date(start)
preds <- probe_set |>
mutate(date = as_date(as_datetime(timestamp))) |>
left_join(movie_avgs, by='movieId') |>
left_join(user_avgs, by='userId') |>
left_join(date_smoothed_effect, by='date') |>
#mutate(diu_smth = d_iu_smth) |>
mutate(pred = mu + b_i + b_u + de_smoothed) |>
pull(pred)
RMSE(preds, probe_set$rating)
#> [1] 0.8669269
