```{r setup, include=FALSE, echo = FALSE}
r.path <- "../r"
src.folder <- "src"
support_scripts.folder <- "support-scripts"
support_functions.folder <- "support-functions"

r.src.path <- file.path(r.path, src.folder)
support_scripts.path <- file.path(r.src.path, support_scripts.folder)
support_functions.path <- file.path(r.src.path, support_functions.folder)
## Setup -----------------------------------------------------------------------
setup_script.file_path <- file.path(support_scripts.path,
                                               "setup.R")

# main_script.file_path <- file.path(r.src.path,
#                                    "capstone-movielens.main.R")
# stop(main_script.file_path)
stopifnot(file.exists(setup_script.file_path))

source(setup_script.file_path, 
       local = knitr::knit_global())
# or sys.source("your-script.R", envir = knitr::knit_global())

## External Common Helper functions -------------------------------------
# common_helper_functions.file_path <- file.path(support_functions.path,
#                                             "common-helper.functions.R")
# source(common_helper_functions.file_path, 
#        local = knitr::knit_global())

# knitr::knit_global()
#knitr::opts_chunk$set(echo = FALSE)
```


---
title: "Capstone Movielens Report"
author: "Azamat Kurbanaev"
date: "`r Sys.Date()`"
bibliography: references.bib
#csl: bit-numerical-mathematics.csl 
envir:
  parent.frame()
output: 
  bookdown::pdf_document2: 
    df_print: paged
    toc: true
    fig_caption: true
    keep_tex: true
    citation_package: biblatex
colorlinks: true
linkcolor: red
citecolor: blue
header-includes:
    - \usepackage{awesomebox}
    - \usepackage{hyperref}
    - \usepackage[natbib=true, 
                  style=numeric, 
                  backref=true, 
                  sorting=none]{biblatex}
    - \hypersetup{backref,
          pdfpagemode=Normal,
          colorlinks=true,
          implicit=false}
vignette: >
  %\VignetteIndexEntry{RMarkdown Citations - Numeric Style}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::knitr}
---

\newenvironment{infobox}[1]
  {
  \begin{itemize}
  \renewcommand{\labelitemi}{
    \raisebox{-.7\height}[0pt][0pt]{
      {\setkeys{Gin}{width=3em,keepaspectratio}
        \includegraphics{images/#1}}
    }
  }
  \setlength{\fboxsep}{1em}
  \begin{blackbox}
  \item
  }
  {
  \end{blackbox}
  \end{itemize}
  }


## Introduction / Overview / Executive Summary

The goal of the project is to build a Recommendation System using a [10M version of the MovieLens dataset](http://grouplens.org/datasets/movielens/10m/).
Following the [Netflix Grand Prize Contest](https://archive.nytimes.com/bits.blogs.nytimes.com/2009/09/21/netflix-awards-1-million-prize-and-starts-a-new-contest/index.html) requirements, we will evaluate the _Root Mean Square Error_ (_RMSE_) score, which, as shown in [Section 23.2 Loss function](https://rafalab.dfci.harvard.edu/dsbook-part-2/highdim/regularization.html#sec-netflix-loss-function) of the _Course Textbook_, is defined as:
$$
\mbox{RMSE} = \sqrt{\frac{1}{N} \sum_{i,j}^{N} (y_{i,j} - \hat{y}_{i,j})^2}
$$

with $N$ being the number of user/movie combinations for which we make predictions and the sum occurring over all these combinations[@IDS2_23-2].

Our goal is to achieve a value of less than 0.86490 (compare with the _Netflix Grand Prize_ requirement: of at least 0.8563[@BigChaosSln]). 


### Datasets Overview

To start with we have to generate two datasets derived from the _MovieLens_ one mentioned above:

* **edx:** we use it to develop and train our algorithms;
* **final_holdout_test:**  according to the course requirements, we use it exclusively to evaluate the _**RMSE**_ of our final algorithm.

For this purpose the following package has been developed by the author of this report: `edx.capstone.movielens.data`. The source code of the package is available [on GitHub](https://github.com/AzKurban-edX-DS/edx.capstone.movielens.data)[@edx_capstone_movielens_data].

Let's install the development version of this package from the GitHub repository and attach the correspondent library to the global environment:
```{r eval=FALSE }
if(!require(edx.capstone.movielens.data)) pak::pak("AzKurban-edX-DS/edx.capstone.movielens.data")

library(edx.capstone.movielens.data)
edx <- edx.capstone.movielens.data::edx
final_holdout_test <- edx.capstone.movielens.data::final_holdout_test
```

Now, we have the datasets listed above:
```{r }
summary(edx)
```

```{r }
summary(final_holdout_test)
```

#### `edx` Dataset
\
Let's look into the details of the `edx` dataset:
``` {r echo = TRUE}
str(edx)
```
Note that we have 9000055 rows and six columns in there:  
```{r }
dim_edx <- dim(edx)
print(dim_edx)
```

First, let's note that we have 10677 different movies: 
```{r}
n_movies <- n_distinct(edx$movieId)
print(n_movies)
```
and 69878 different users in the dataset:
```{r}
n_users <- n_distinct(edx$userId)
print(n_users)
```

Now, note the expressions below which confirm the fact explained in [Section _23.1.1 Movielens data_](https://rafalab.dfci.harvard.edu/dsbook-part-2/highdim/regularization.html#movielens-data) of the _Course Textbook_[@IDS2] that not every user rated every movie:
```{r}
max_possible_ratings <- n_movies*n_users
sprintf("Maximum possible ratings: %s", max_possible_ratings)
sprintf("Rows in `edx` dataset: %s", dim_edx[1])
sprintf("Not every movie was rated: %s", max_possible_ratings > dim_edx[1])

```

As also explained in that section, we can think of these data as a very large matrix, with users on the rows and movies on the columns, with many empty cells. Therefore, we can think of a recommendation system as filling in the `NA`s in the dataset for the movies that some or all the users do not rate. A sample from the `edx` data below illustrates this idea[@IDS2_23-1-1]: 
```{r}
keep <- edx |> 
  dplyr::count(movieId) |> 
  top_n(4, n) |> 
  pull(movieId)

tab <- edx |> 
  filter(movieId %in% keep) |> 
  filter(userId %in% c(13:20)) |> 
  select(userId, title, rating) |> 
  mutate(title = str_remove(title, ", The"),
         title = str_remove(title, ":.*")) |>
  pivot_wider(names_from = "title", values_from = "rating")

print(tab)
```

The following plot of the matrix for a random sample of 100 movies and 100 users with yellow indicating a user/movie combination for which we have a rating shows how _sparse_ the matrix is:
```{r sparsity-of-movie-recs, echo=TRUE, fig.width=3, fig.height=3, out.width="40%"}
users <- sample(unique(edx$userId), 100)

rafalib::mypar()
edx|> 
  filter(userId %in% users) |> 
  select(userId, movieId, rating) |>
  mutate(rating = 1) |>
  pivot_wider(names_from = movieId, values_from = rating) |> 
  (\(mat) mat[, sample(ncol(mat), 100)])() |>
  as.matrix() |> 
  t() |>
  image(1:100, 1:100, z = _ , xlab = "Movies", ylab = "Users")
```

Further observations highlighted there that, as we can see from the distributions the author presented, some movies get rated more than others, and some users are more active than others in rating movies:
```{r movie-id-and-user-hists, echo=TRUE, fig.width=6, fig.height=3}
p1 <- edx |> 
  count(movieId) |> 
  ggplot(aes(n)) + 
  geom_histogram(bins = 30, color = "black") + 
  scale_x_log10() + 
  ggtitle("Movies")

p2 <- edx |> 
  count(userId) |> 
  ggplot(aes(n)) + 
  geom_histogram(bins = 30, color = "black") + 
  scale_x_log10() + 
  ggtitle("Users")

gridExtra::grid.arrange(p2, p1, ncol = 2)
```

Finally, we can see that no movies have a rating of 0. Movies are rated from 0.5 to 5.0 in 0.5 increments:
```{r }
#library(dplyr)
s <- edx |> group_by(rating) |>
  summarise(n = n())
print(s)
```

Further analysis of the `edx` dataset have been also inspired by the article mentioned above[@MRS-R-BEST], from which the code and explanatory notes below were cited.

##### Rating distribution plot[@MRS-R-BEST]
\
The code below demonstrates another way of visualizing the rating distribution:
```{r}
edx |>
  group_by(rating) |>
  summarize(count = n()) |>
  ggplot(aes(x = rating, y = count)) +
  geom_bar(stat = "identity", fill = "#8888ff") +
  ggtitle("Rating Distribution") +
  xlab("Rating") +
  ylab("Occurrences Count") +
  scale_y_continuous(labels = comma) +
  scale_x_continuous(n.breaks = 10) +
  theme_economist() +
  theme(axis.title.x = element_text(vjust = -5, face = "bold"), 
        axis.title.y = element_text(vjust = 10, face = "bold"), 
        plot.margin = margin(0.7, 0.5, 1, 1.2, "cm"))

```

This graph is another confirmation of what we found out above: rounded ratings occur more often than half-stared ones. The upward trend previously discussed is now perfectly clear, although it seems to top right between the 3 and 4-star ratings lowering the occurrences count afterward. That might be due to users being more hesitant to rate with the highest mark for whichever reasons they might hold[@MRS-R-BEST].


##### Ratings per movie
\

###### Movie popularity count[@MRS-R-BEST]
\
```{r}
print(edx |> 
  group_by(movieId) |> 
  summarize(count = n()) |>
  slice_head(n = 10)
)
```

```{r}
summary(edx |> group_by(movieId) |> summarize(count = n()) |> select(count))
```


###### Ratings per movie plot[@MRS-R-BEST]
\
```{r}
edx |>
  group_by(movieId) |>
  summarize(count = n()) |>
  ggplot(aes(x = movieId, y = count)) +
  geom_point(alpha = 0.2, color = "#4020dd") +
  geom_smooth(color = "red") +
  ggtitle("Ratings per movie") +
  xlab("Movies") +
  ylab("Number of ratings") +
  scale_y_continuous(labels = comma) +
  scale_x_continuous(n.breaks = 10) +
  theme_economist() +
  theme(axis.title.x = element_text(vjust = -5, face = "bold"), 
        axis.title.y = element_text(vjust = 10, face = "bold"), 
        plot.margin = margin(0.7, 0.5, 1, 1.2, "cm"))
```


###### Movies' rating histogram[@MRS-R-BEST]
\
```{r}
edx |>
  group_by(movieId) |>
  summarize(count = n()) |>
  ggplot(aes(x = count)) +
  geom_histogram(fill = "#8888ff", color = "#4020dd") +
  ggtitle("Movies' rating histogram") +
  xlab("Rating count") +
  ylab("Number of movies") +
  scale_y_continuous(labels = comma) +
  scale_x_log10(n.breaks = 10) +
  theme_economist() +
  theme(axis.title.x = element_text(vjust = -5, face = "bold"), 
        axis.title.y = element_text(vjust = 10, face = "bold"), 
        plot.margin = margin(0.7, 0.5, 1, 1.2, "cm"))
```


##### Ratings per user[@MRS-R-BEST]
\

###### User rating count (activity measure)
\
```{r}
print(edx |> 
  group_by(userId) |> 
  summarize(count = n()) |>
  slice_head(n = 10)
)
```


###### User rating summary
\
```{r}
summary(edx |> group_by(userId) |> summarize(count = n()) |> select(count))
```

###### Ratings per user plot
\
```{r}
edx |>
  group_by(userId) |>
  summarize(count = n()) |>
  ggplot(aes(x = userId, y = count)) +
  geom_point(alpha = 0.2, color = "#4020dd") +
  geom_smooth(color = "red") +
  ggtitle("Ratings per user") +
  xlab("Users") +
  ylab("Number of ratings") +
  scale_y_continuous(labels = comma) +
  scale_x_continuous(n.breaks = 10) +
  theme_economist() +
  theme(axis.title.x = element_text(vjust = -5, face = "bold"), 
        axis.title.y = element_text(vjust = 10, face = "bold"), 
        plot.margin = margin(0.7, 0.5, 1, 1.2, "cm"))
```

###### Users' rating histogram
\
```{r}
edx |>
  group_by(userId) |>
  summarize(count = n()) |>
  ggplot(aes(x = count)) +
  geom_histogram(fill = "#8888ff", color = "#4020dd") +
  ggtitle("Users' rating histogram") +
  xlab("Rating count") +
  ylab("Number of users") +
  scale_y_continuous(labels = comma) +
  scale_x_log10(n.breaks = 10) +
  theme_economist() +
  theme(axis.title.x = element_text(vjust = -5, face = "bold"), 
        axis.title.y = element_text(vjust = 10, face = "bold"), 
        plot.margin = margin(0.7, 0.5, 1, 1.2, "cm"))
```

## Methods / Analysis
::: {.noteblock data-latex=""}
All the source code of the R-scripts is available on the project's [GitHub repository](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/tree/main/r/src)[@edx_capstone_movielens]. 
:::

### Defining Logging and Time Measuring Helper Functions
\

First, let's define some helper functions for logging and time-measuring features that we will use in our R scripts. Some of them are listed below:

```{r eval=FALSE }
## Logging Helper functions -----------------------------------------------------
open_logfile <- function(file_name){
  log_file_name <- as.character(Sys.time()) |> 
    str_replace_all(':', '_') |> 
    str_replace(' ', 'T') |>
    str_c(file_name)
  
  log_open(file_name = log_file_name)
}
print_start_date <- function(){
  print(date())
  Sys.time()
}
put_start_date <- function(){
  put(date())
  Sys.time()
}
print_end_date <- function(start){
  print(date())
  print(Sys.time() - start)
}
put_end_date <- function(start){
  put(date())
  put(Sys.time() - start)
}

msg.set_arg <- function(msg_template, arg, arg.name = "%1") {
  msg_template |> 
    str_replace_all(arg.name, as.character(arg))
}
msg.glue <- function(msg_template, arg, arg.name = "%1"){
  msg_template |>
    msg.set_arg(arg, arg.name) |>
    str_glue()
}

print_log <- function(msg){
  print(str_glue(msg))
}
put_log <- function(msg){
  put(str_glue(msg))
}

get_log1 <- function(msg_template, arg1) {
  str_glue(str_replace_all(msg_template, "%1", as.character(arg1)))
}
print_log1 <- function(msg_template, arg1){
  print(get_log1(msg_template, arg1))
}
put_log1 <- function(msg_template, arg1){
  put(get_log1(msg_template, arg1))
}

get_log2 <- function(msg_template, arg1, arg2) {
  msg_template |> 
    str_replace_all("%1", as.character(arg1)) |>
    str_replace_all("%2", as.character(arg2)) |>
    str_glue()
}
print_log2 <- function(msg_template, arg1, arg2){
  print(get_log1(msg_template, arg1, arg2))
}
put_log2 <- function(msg_template, arg1, arg2){
  put(get_log1(msg_template, arg1, arg2))
}

# ...
```

::: {.noteblock data-latex=""}
The full source code of these functions is available in the [Logging Helper functions](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R#L20) section of the [capstone-movielens.main.R](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R) script on _GitHub_.
:::

### Preparing train and set datasets
\

We will split the `edx` dataset into a training set, which we will use to build and train our models, and a test set in which we will compute the accuracy of our predictions, the way described in [Section 23.1.1 Movielens data](https://rafalab.dfci.harvard.edu/dsbook-part-2/highdim/regularization.html#movielens-data) of the _Course Textbook_ mentioned above[@IDS2_23-1-1].We will also use the _5-Fold Cross Validation_ method as described in [Section 29.6 Cross validation](https://rafalab.dfci.harvard.edu/dsbook-part-2/ml/resampling-methods.html#cross-validation) of the _Course Textbook_. 
To prepare datasets for processing, we will use the following functions, specifically designed for these operations:
```{r eval=FALSE }
make_source_datasets()
init_source_datasets()
```

::: {.noteblock data-latex=""}
The full source code of the function listed above is available in the [Initialize input datasets](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/data.helper.functions.R#L86) section of the [data.helper.functions.R](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/data.helper.functions.R) script on _GitHub_.
:::

#### The `make_source_datasets` function
\

Let's take a closer look at the objects we will receive as a result of executing this function.

```{r eval=FALSE}

make_source_datasets <- function(){
  # ...
  list(edx_CV = edx_CV,
       edx.mx = edx.mx,
       edx.sgr = edx.sgr,
       tuning_sets = tuning_sets,
       movie_map = movie_map,
       date_days_map = date_days_map)
}
```

##### `edx.mx` Matrix Object
\

We will use the array representation described in [Section 17.5 of the Textbook](https://rafalab.dfci.harvard.edu/dsbook-part-2/linear-models/treatment-effect-models.html#sec-anova), for the training data: we denote ranking for movie $j$ by user $i$ as $y_{i,j}$. To create this matrix, we use `tidyr::pivot_wider` function:

```{r eval=FALSE}

  put_log("Function: `make_source_datasets`: Creating Rating Matrix from `edx` dataset...")
  edx.mx <- edx |> 
    mutate(userId = factor(userId),
           movieId = factor(movieId)) |>
    select(movieId, userId, rating) |>
    pivot_wider(names_from = movieId, values_from = rating) |>
    column_to_rownames("userId") |>
    as.matrix()
  
  put_log("Function: `make_source_datasets`:
Matrix created: `edx.mx` of the following dimentions:")

```

```{r}
  str(edx.mx)
```

##### `edx.sgr` Object
\

To account for the Movie Genre Effect more accurately, we need a dataset with split rows for movies belonging to multiple genres:
```{r eval=FALSE}
  put_log("Function: `make_source_datasets`: 
To account for the Movie Genre Effect, we need a dataset with split rows 
for movies belonging to multiple genres.")
  edx.sgr <- splitGenreRows(edx)
```
```{r}
str(edx.sgr)
summary(edx.sgr)
```

Note that we use the `splitGenreRows` function to split rows of the original dataset:
```{r eval=FALSE}
splitGenreRows <- function(data){
  put("Splitting dataset rows related to multiple genres...")
  start <- put_start_date()
  gs_splitted <- data |>
    separate_rows(genres, sep = "\\|")
  put("Dataset rows related to multiple genres have been splitted to have single genre per row.")
  put_end_date(start)
  gs_splitted
}
```

::: {.noteblock data-latex=""}
The source code of the function mentioned above is also available in the [Initialize input datasets](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/data.helper.functions.R#L86) section of the [data.helper.functions.R](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/data.helper.functions.R) script on _GitHub_.
:::

##### `movie_map` Object
\

To be able to map movie IDs to titles we create the following lookup table:
```{r eval=FALSE}
movie_map <- edx |> select(movieId, title, genres) |> 
    distinct(movieId, .keep_all = TRUE)
  
  put_log("Function: `make_source_datasets`: Dataset created: movie_map")
```

```{r}
str(movie_map)
summary(movie_map)
```

Note that titles cannot be considered unique, so we can't use them as IDs[@IDS2_23-1-1].


##### `date_days_map` Object
\

We have a `timestamp` field in the `edx` dataset.
To be able to map the date, year, and number of days since the earliest record in the `edx` dataset with the corresponding value in this field, we create the following lookup table:
```{r eval=FALSE}
  put_log("Function: `make_source_datasets`: Creating Date-Days Map dataset...")
  date_days_map <- edx |>
    mutate(date_time = as_datetime(timestamp)) |>
    mutate(date = as_date(date_time)) |>
    mutate(year = year(date_time)) |>
    mutate(days = as.integer(date - min(date))) |>
    select(timestamp, date_time, date, year, days) |>
    distinct(timestamp, .keep_all = TRUE)
  
  put_log("Function: `make_source_datasets`: Dataset created: date_days_map")
```
``` {r}
  str(date_days_map)
  summary(date_days_map)
```

##### `edx_CV` Object
\

Here we have a list of sample objects we need to perform the _5-Fold Cross Validation_ 
as explained in [Section 29.6.1 K-fold cross validation](https://rafalab.dfci.harvard.edu/dsbook-part-2/ml/resampling-methods.html#k-fold-cross-validation) of the _Course Textbook_:
```{r eval=FALSE}
  start <- put_start_date()
  edx_CV <- lapply(kfold_index,  function(fold_i){
    
    put_log1("Method `make_source_datasets`: 
Creating K-Fold Cross Validation Datasets, Fold %1", fold_i)
    
    #> We split the initial datasets into training sets, which we will use to build 
    #> and train our models, and validation sets in which we will compute the accuracy 
    #> of our predictions, the way described in the `Section 23.1.1 Movielens data`
    #> (https://rafalab.dfci.harvard.edu/dsbook-part-2/highdim/regularization.html#movielens-data) 
    #> of the Course Textbook.
    
    split_sets <- edx |>
      sample_train_validation_sets(fold_i*1000)
    
    train_set <- split_sets$train_set
    validation_set <- split_sets$validation_set
    
    put_log("Function: `make_source_datasets`: 
Sampling 20% from the split-row version of the `edx` dataset...")
    split_sets.gs <- edx.sgr |>
      sample_train_validation_sets(fold_i*2000)

    train.sgr <- split_sets.gs$train_set
    validation.sgr <- split_sets.gs$validation_set
    
    # put_log("Function: `make_source_datasets`: Dataset created: validation.sgr")
    # put(summary(validation.sgr))
    
    #> We will use the array representation described in `Section 17.5 of the Textbook`
    #> (https://rafalab.dfci.harvard.edu/dsbook-part-2/linear-models/treatment-effect-models.html#sec-anova), 
    #> for the training data. 
    #> To create this matrix, we use `tidyr::pivot_wider` function:
    
    put_log("Function: `make_source_datasets`: Creating Rating Matrix from Train Set...")
    train_mx <- train_set |> 
      mutate(userId = factor(userId),
             movieId = factor(movieId)) |>
      select(movieId, userId, rating) |>
      pivot_wider(names_from = movieId, values_from = rating) |>
      column_to_rownames("userId") |>
      as.matrix()
    
    put_log("Function: `make_source_datasets`:
Matrix created: `train_mx` of the following dimentions:")
    put(dim(train_mx))


    list(train_set = train_set,
         train_mx = train_mx,
         train.sgr = train.sgr,
         validation_set = validation_set)
  })
  put_end_date(start)
  put_log("Function: `make_source_datasets`: 
Set of K-Fold Cross Validation datasets created: edx_CV")
```
```{r}
str(edx_CV)
```

::: {.noteblock data-latex=""}
This code snippet is a [part](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/data.helper.functions.R#L140) of the [make_source_datasets](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/data.helper.functions.R#L87) _function_ code described above.
:::

Note that we used the `sample_train_validation_sets` function call to split the original dataset (`edx` in this case): 
```{r eval=FALSE}
    split_sets <- edx |>
      sample_train_validation_sets(fold_i*1000)
```

which returns a pair of train/validation sets:
```{r eval=FALSE}
sample_train_validation_sets <- function(data, seed){
  put_log("Function: `sample_train_validation_sets`: Sampling 20% of the `data` data...")
  set.seed(seed)
  validation_ind <- 
    sapply(splitByUser(data),
           function(i) sample(i, ceiling(length(i)*.2))) |> 
    unlist() |> 
    sort()
  
  put_log("Function: `sample_train_validation_sets`: 
Extracting 80% of the original `data` not used for the Validation Set, 
excluding data for users who provided no more than a specified number of ratings: {min_nratings}.")
  
  train_set <- data[-validation_ind,]
  
  put_log("Function: `sample_train_validation_sets`: Dataset created: train_set")
  put(summary(train_set))
  
  put_log("Function: `sample_train_validation_sets`: 
To make sure we don’t include movies in the Training Set that should not be there, 
we exclude entries using the semi_join function from the Validation Set.")
  tmp.data <- data[validation_ind,]
  
  validation_set <- tmp.data |> 
    semi_join(train_set, by = "movieId") |> 
    semi_join(train_set, by = "userId") |>
    as.data.frame()
  
  # Add rows excluded from `validation_set` into `train_set`
  tmp.excluded <- anti_join(tmp.data, validation_set)
  train_set <- rbind(train_set, tmp.excluded)
  
  put_log("Function: `sample_train_validation_sets`: Dataset created: validation_set")
  put(summary(validation_set))

  # CV train & test sets Consistency Test
  validation.left_join.Nas <- train_set |>
    mutate(tst.col = rating) |>
    select(userId, movieId, tst.col) |>
    data.consistency.test(validation_set)
  
  put_log("Function: `sample_train_validation_sets`:
Below are the data consistency verification results")
  put(validation.left_join.Nas)
  
  # Return result datassets ----------------------------------------------------    
  list(train_set = train_set, 
       validation_set = validation_set)
}

```

::: {.noteblock data-latex=""}
The [sample_train_validation_sets](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/data.helper.functions.R#L15) function is defined in the same script as the [make_source_datasets](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/data.helper.functions.R#L87)` one, from where it is called.
:::

#### Common Helper Functions
\

For our further analysis, we are going to use the following _common helper functions_:

##### `clamp` function
\

As explained in [Section  24.4 User effects](https://rafalab.dfci.harvard.edu/dsbook-part-2/highdim/regularization.html#user-effects) of the _Course Textbook_ we know ratings can’t be below 0.5 or above 5. For this reason, we will use the `clamp` function described in that section:
```{r eval=FALSE}
clamp <- function(x, min = 0.5, max = 5) pmax(pmin(x, max), min)
```

##### Functions to calculate _(Root) Mean Squared Error_
\

We will need the following functions to calculate _(R)MSEs_:
```{r eval=FALSE}
mse <- function(r) mean(r^2)

mse_cv <- function(r_list) {
  mses <- sapply(r_list, mse(r))
  mean(mses)
}

rmse <- function(r) sqrt(mse(r))
# rmse_cv <- function(r_list) sqrt(mse_cv(r_list))

rmse2 <- function(true_ratings, predicted_ratings) {
  rmse(true_ratings - predicted_ratings)
}
```

::: {.noteblock data-latex=""}
All the _common helper functions_, including those described above, are defined in the [common-helper.functions.R](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/common-helper.functions.R) script on _GitHub_. 
:::

### Overall Mean Rating (Naive) Model
\

Let's begin our analysis by evaluating the simplest model described in [Section _23.3 The First Model_ of the *Course Textbook*](https://rafalab.dfci.harvard.edu/dsbook-part-2/highdim/regularization.html#a-first-model), and then gradually refine it through further research.
It is about a model that assumes the same rating for all movies and users with all the differences explained by random variation would look as follows:

$$
Y_{i,j} = \mu + \varepsilon_{i,j}
$$

with $\varepsilon_{i,j}$ independent errors sampled from the same distribution centered at 0 and $\mu$ the _true_ rating for all movies.

We know that the estimate that minimizes the RMSE is the least squares estimate of $\mu$ and, in this case, is the average of all ratings:

```{r pressure, echo=TRUE}
mu <- mean(edx$rating)
print(mu)
```

If we predict all unknown ratings with $\hat{\mu}$, we obtain the following RMSE: 
```{r}
mu.MSEs <- naive_model_MSEs(mu)
data.frame(fold_No = 1:5, MSE = mu.MSEs) |>
  data.plot(title = "MSE resuls of the 5-fold CV method applied to the Overall Mean Rating Model",
              xname = "fold_No", 
              yname = "MSE")

mu.RMSE <- sqrt(mean(mu.MSEs))
mu.RMSE
```
::: {.noteblock data-latex=""}
For the _Mean Squared Error_ data visualization we used [data.plot](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/data.helper.functions.R#L592) function] defined in the [Data Visualization](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/data.helper.functions.R#L447) section of the [data.helper.function.R](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/data.helper.functions.R) script.
:::

```{r eval=FALSE}
data.plot <- function(data, 
                      title, 
                      xname, 
                      yname, 
                      xlabel = NULL, 
                      ylabel = NULL,
                      line_col = "blue",
                      # scale = 1,
                      normalize = FALSE) {
  y <- data[, yname]
  
  if (normalize) {
    y <- y - min(y)
  }
  
  if (is.null(xlabel)) {
    xlabel = xname
  }
  if (is.null(ylabel)) {
    ylabel = yname
  }
  
  aes_mapping <- aes(x = data[, xname], y = y)
  
  data |> 
    ggplot(mapping = aes_mapping) +
    ggtitle(title) +
    xlab(xlabel) +
    ylab(ylabel) +
    geom_point() + 
    geom_line(color=line_col)
}
```

Here we also used [naive_model_MSEs](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/common-helper.functions.R#L54) function defined in the [common-helper.functions.R](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/common-helper.functions.R) script (already mentioned above) to compute _Mean Squared Errors_ using _5-Fold Cross Validation_ method: 

```{r eval=FALSE }
naive_model_MSEs <- function(val) {
  sapply(edx_CV, function(cv_item){
    mse(cv_item$validation_set$rating - val)
  })
}
```

One more function, defined in the [same script](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/common-helper.functions.R), that we will need for further analysis of the current model, is the [naive_model_RMSE](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/common-helper.functions.R#L59) one:
```{r eval=FALSE }
naive_model_RMSE <- function(val){
  sqrt(mean(naive_model_MSEs(val)))
}
```

#### Ensure that `mu.RMSE` value is the best for the current model
\

If we plug in any other number, we will get a higher RMSE. Let's prove that by the following small investigation:
```{r }
  deviation <- seq(0, 6, 0.1) - 3

  deviation.RMSE <- sapply(deviation, function(delta){
    naive_model_RMSE(mu + delta)
  })
```

Let's make a quick investigation of the `deviation.RMSE` result we have just got: 
```{r}
data.frame(delta = deviation, 
           delta.RMSE = deviation.RMSE) |> 
data.plot(title = TeX(r'[RMSE as a function of deviation ($\delta$) from the Overall Mean Rating ($\hat{mu}$)]'),
              xname = "delta", 
              yname = "delta.RMSE", 
              xlabel = TeX(r'[$\delta$]'), 
              ylabel = "RMSE")

which_min_deviation <- deviation[which.min(deviation.RMSE)]
min_rmse = min(deviation.RMSE)

print_log1("Minimum RMSE is achieved when the deviation from the mean is: %1",
         which_min_deviation)

print_log1("Is the previously computed RMSE the best for the current model: %1",
         mu.RMSE == min_rmse)
```
```{r eval=FALSE}
RMSEs.ResultTibble.OMR <- RMSEs.ResultTibble |> 
  RMSEs.AddRow("Overall Mean Rating Model", mu.RMSE)
```
```{r}
RMSE_kable(RMSEs.ResultTibble.OMR)
```

To win the grand prize of $1,000,000, a participating team had to get an RMSE of at least 0.8563[@BigChaosSln]. So we can definitely do better![@IDS2_23-3]

### User Effect Model
\
To improve our model let's now take into consideration user effects as explained in [Section _23.4 User effects_](https://rafalab.dfci.harvard.edu/dsbook-part-2/highdim/regularization.html#user-effects) of the *Course Textbook*. 
If we visualize the average rating for each user the way the [the author](https://x.com/rafalab) shows, we can see that there is substantial variability in the average ratings across users: 
```{r}
hist(edx.user_mean_ratings$mean_rating, nclass = 30)
```

Following the author's further explanation, to account for this variability, we will use a linear model with a _treatment effect_  $\alpha_i$ for each user. The sum $\mu+\alpha_i$ can be interpreted as the typical rating user $i$ gives to movies. So we write the model as follows:

$$
Y_{i,j} = \mu + \alpha_i + \varepsilon_{i,j}
$$

Statistics textbooks refer to the $\alpha$s as treatment effects. In the Netflix challenge papers, they refer to them as _bias_[@IDS2_23-4; @MFT_RS].

As it is stated here[@IDS2_23-4], it can be shown that the least squares estimate $\hat{\alpha}_i$ is just the average of $y_{i,j} - \hat{\mu}$ for each user $i$. So we can compute them this way:
```{r eval=FALSE}
a <- rowMeans(y - mu, na.rm = TRUE)
```

These considerations alows us to compute a _User Mean Ratings_ the following way:
```{r eval=FALSE}
put_log("Computing Average Ratings per User (User Mean Ratings)...")
user.mean_ratings <- rowMeans(edx.mx, na.rm = TRUE)
user_ratings.n <- rowSums(!is.na(edx.mx))
  
edx.user_mean_ratings <- 
  data.frame(userId = names(user.mean_ratings), 
             mean_rating = user.mean_ratings,
             n = user_ratings.n)
  
put_log("User Mean Ratings have been computed.")
```
```{r}
str(edx.user_mean_ratings)
```

And then we compute a _User Effect_ this way:
```{r eval=FALSE}
put_log("Computing User Effect per users ...")
edx.user_effect <- edx.user_mean_ratings |>
  mutate(userId = as.integer(userId),
         a = mean_rating - mu)

put_log("A User Effect Model has been builded")
```
```{r}
par(cex = 0.7)
hist(edx.user_effect$a, 30, xlab = TeX(r'[$\hat{alpha}_{i}$]'),
     main = TeX(r'[Histogram of $\hat{alpha}_{i}$]'))

str(edx.user_effect)
```

::: {.noteblock data-latex=""}
The full source code of the _User Effect_ computation is available in the [Model building: User Effect](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R#L531) section of the [capstone-movielens.main.R](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R) script on _GitHub_.
:::

Finally, we are ready to compute the `RMSE` (additionally using the [clamp](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/common-helper.functions.R#L4) helper function we defined above to keep predictions in the proper range):
```{r eval=FALSE}
put_log("Computing the RMSE taking into account user effects...")
start <- put_start_date()
edx.user_effect.MSEs <- sapply(edx_CV, function(cv_fold_dat){
  cv_fold_dat$validation_set |>
    left_join(edx.user_effect, by = "userId") |>
    mutate(resid = rating - clamp(mu + a)) |> 
    pull(resid) |> mse()
})
put_end_date(start)

edx.user_effect.RMSE <- sqrt(mean(edx.user_effect.MSEs))

RMSEs.ResultTibble.UE <- RMSEs.ResultTibble.OMR |> 
  RMSEs.AddRow("User Effect Model", edx.user_effect.RMSE)
```
```{r}
data.frame(fold_No = 1:5, MSE = edx.user_effect.MSEs) |>
  data.plot(title = "MSE resuls of the 5-fold CV method applied to the User Effect Model",
            xname = "fold_No", 
            yname = "MSE")

RMSE_kable(RMSEs.ResultTibble.UE)
```



::: {.noteblock data-latex=""}
The full source code of the _User Effect Model RMSE_ computation is available in the [Compute RMSE for User Effect Model](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R#L655) section of the [capstone-movielens.main.R](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R) script on _GitHub_.
:::

### User+Movie Effect (UME) Model
\

In [23.5 Movie effects](https://rafalab.dfci.harvard.edu/dsbook-part-2/highdim/regularization.html#movie-effects) section of the *Course Textbook* the author draws our attention to the fact that some movies are generally rated higher than others. He also explains that a linear model with a _treatment effect_ $\beta_j$ for each movie can be used in this case, which can be interpreted as movie effect or the difference between the average ranking for movie $j$ and the overall average $\mu$: 

$$
Y_{i,j} = \mu + \alpha_i + \beta_j +\varepsilon_{i,j}
$$
The author then shows how to use an approximation by first computing the least square estimate $\hat{\mu}$ and $\hat{\alpha}_i$, and then estimating $\hat{\beta}_j$ as the average of the residuals $y_{i,j} - \hat{\mu} - \hat{\alpha}_i$:

```{r eval=FALSE}
b <- colMeans(y - mu - a, na.rm = TRUE)
```

Inspired by this idea, a few support functions were developed by the author of this report, which we will use for our further analysis.

#### UME Model: Support Functions
\

::: {.noteblock data-latex=""}
The full source code of the functions described in this section is available in the [User+Movie Effect Model Functions](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/UM-effect.functions.R#L1) section of the [UM-effect.functions.R](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/UM-effect.functions.R) script on _GitHub_.
:::
 
##### `train_user_movie_effect` Function
\

We use this function to build and train our model using the `train_set` dataset:
```{r eval=FALSE}
train_user_movie_effect <- function(train_set, lambda = 0){
  if (is.na(lambda)) {
    stop("Function: train_user_movie_effect
`lambda` is `NA`")
  }

  UM.effect <- train_set |>
    left_join(edx.user_effect, by = "userId") |>
    mutate(resid = rating - (mu + a)) |> 
    group_by(movieId) |>
    summarise(b = mean_reg(resid, lambda), n = n())
  
  stopifnot(!is.na(mean(UM.effect$b)))
  UM.effect
}
```

::: {.noteblock data-latex=""}
The function described above accepts the `lambda` parameter, which we will need later for the _Regularization_ method. We also use the [mean_reg](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/common-helper.functions.R#L63) function call, which we will also need for the *Regularization*.
We will explain that later in the [Regularization Method] section. 
For now, we omit the `lambda` parameter, accepting its default value `lambda = 0`. In this case, the `mean_reg` function is equivalent to the simple `mean` one.
:::

```{r eval=FALSE}
## Regularization --------------------------------------------------------------
mean_reg <- function(vals, lambda = 0, na.rm = TRUE){
  if (is.na(lambda)) {
    stop("Function: mean_reg
`lambda` is `NA`")
  }
  
  names(lambda) <- NULL
  sums <- sum(vals, na.rm = na.rm)
  N <- ifelse(na.rm, sum(!is.na(vals)), length(vals))
  sums/(N + lambda)
}
```

##### `train_user_movie_effect.cv` Function
\

We use the [train_user_movie_effect.cv](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/UM-effect.functions.R#L17) function to build and train our model using the `5-Fold Cross Validation` method. Below, we provide the most important part of the code of that function:
```{r eval=FALSE}
train_user_movie_effect.cv <- function(lambda = 0){
# ...
  start <- put_start_date()
  user_movie_effects_ls <- lapply(edx_CV, function(cv_fold_dat){
    cv_fold_dat$train_set |> train_user_movie_effect(lambda)
  })
  put_end_date(start)
  put_log("Function: train_user_movie_effect.cv:
User+Movie Effect list have been computed")
  
  user_movie_effects_united <- union_cv_results(user_movie_effects_ls)

  user_movie_effect <- user_movie_effects_united |>
    group_by(movieId) |>
    summarise(b = mean(b), n = mean(n))
  # ...
  user_movie_effect
}

```

::: {.noteblock data-latex=""}
Here we use the function call [union_cv_results](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/data.helper.functions.R#L432), which is defined in the script [common-helper.functions.R](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/data.helper.functions.R), to aggregate the `Cross Validation` results.
:::
```{r eval=FALSE}
union_cv_results <- function(data_list) {
  out_dat <- data_list[[1]]
  
  for (i in 2:CVFolds_N){
    out_dat <- union(out_dat, 
                     data_list[[i]])
  }
  
  out_dat
}
```

##### `calc_user_movie_effect_MSE` Function
\

The code of the function [calc_user_movie_effect_MSE](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/UM-effect.functions.R#L55) defined in the [UM-effect.functions.R](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/UM-effect.functions.R) script to calculate the `Mean Squared Error (MSE)` of the `UME Model` for the given `Test Set` is provided below:
```{r eval=FALSE}
calc_user_movie_effect_MSE <- function(test_set, um_effect){
  mse.result <- test_set |>
    left_join(edx.user_effect, by = "userId") |>
    left_join(um_effect, by = "movieId") |>
    mutate(resid = rating - clamp(mu + a + b)) |> 
    pull(resid) |> mse()
  
  stopifnot(!is.na(mse.result))
  mse.result
}
```

##### `calc_user_movie_effect_MSE.cv` Function
\

The code of the function [calc_user_movie_effect_MSE.cv](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/UM-effect.functions.R#L72) defined in the [UM-effect.functions.R](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/UM-effect.functions.R) script to calculate the `5-Fold Cross Validation` MSE result of the `UME Model` is provided below:
```{r eval=FALSE}
calc_user_movie_effect_MSE.cv <- function(um_effect){
  put_log("Function: user_movie_effects_MSE.cv:
Computing the RMSE taking into account User+Movie Effects...")
  start <- put_start_date()
  user_movie_effects_MSEs <- sapply(edx_CV, function(cv_fold_dat){
    cv_fold_dat$validation_set |> calc_user_movie_effect_MSE(um_effect)
  })
  put_end_date(start)
  
  put_log1("Function: user_movie_effects_MSE.cv:
MSE values have been plotted for the %1-Fold Cross Validation samples.", 
           CVFolds_N)
  
  mean(user_movie_effects_MSEs)
}

```


##### `calc_user_movie_effect_RMSE` Function
\


The code of the function [calc_user_movie_effect_RMSE](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/UM-effect.functions.R#L51) defined in the [UM-effect.functions.R](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/UM-effect.functions.R) script to calculate the `Root Mean Squared Error (RMSE)` of the `UME Model` for the given `Test Set` is provided below:

```{r eval=FALSE}
calc_user_movie_effect_RMSE <- function(test_set, um_effect){
  mse <- test_set |> calc_user_movie_effect_MSE(um_effect)
  sqrt(mse)
}
```

##### `calc_user_movie_effect_RMSE.cv` Function
\

The code of the function [calc_user_movie_effect_RMSE.cv](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/UM-effect.functions.R#L65) defined in the [UM-effect.functions.R](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/UM-effect.functions.R) script to calculate the `5-Fold Cross Validation` RMSE result of the `UME Model` is provided below:

```{r eval=FALSE}
calc_user_movie_effect_RMSE.cv <- function(um_effect){
  user_movie_effects_MSE <- calc_user_movie_effect_MSE.cv(um_effect)
  um_effect_RMSE <- sqrt(user_movie_effects_MSE)
  put_log2("Function: user_movie_effects_RMSE.cv:
%1-Fold Cross Validation ultimate RMSE: %2", CVFolds_N, um_effect_RMSE)
  um_effect_RMSE
}

```



#### Model Building
\

::: {.noteblock data-latex=""}
The full source code of builing and training the current model is available in the [Model building: User+Movie Effect](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R#L721) section of the [capstone-movielens.main.R](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R) script on _GitHub_.
:::

Below, we provide the most significant part of the code for training our model using the `5-Fold Cross Validation` method:
```{r eval=FALSE}
  cv.UM_effect <- train_user_movie_effect.cv()
```
```{r}
str(cv.UM_effect)

par(cex = 0.7)
hist(cv.UM_effect$b, 30, xlab = TeX(r'[$\hat{beta}_{j}$)]'),
     main = TeX(r'[Histogram of $\hat{beta}_{j}$]'))
```


We can now construct predictors and see how much the `RMSE` improves[@IDS2_23-5]:
```{r eval=FALSE}
cv.UM_effect.RMSE <- calc_user_movie_effect_RMSE.cv(cv.UM_effect)

RMSEs.ResultTibble.UME <- RMSEs.ResultTibble.UE |> 
  RMSEs.AddRow("User+Movie Effect Model", cv.UM_effect.RMSE)

```
```{r}
RMSE_kable(RMSEs.ResultTibble.UME)
```

### Regularizing User+Movie Effect Model


#### Utilizing Penalized least squares
\
[Section _23.6 Penalized least squares_ of the *Course Textbook*](https://rafalab.dfci.harvard.edu/dsbook-part-2/highdim/regularization.html#penalized-least-squares) explains why and how we should use _Penalized least squares_ to improve our predictions. The author also explains that the general idea of penalized regression is to control the total variability of the movie effects: $\sum_{j=1}^n \beta_j^2$. Specifically, instead of minimizing the least squares equation, we minimize an equation that adds a penalty:

$$ 
\sum_{i,j} \left(y_{u,i} - \mu - \alpha_i - \beta_j \right)^2 + \lambda \sum_{j} \beta_j^2
$$
The first term is just the sum of squares and the second is a penalty that gets larger when many $\beta_i$s are large. Using calculus, we can actually show that the values of $\beta_i$ that minimize this equation are:

$$
\hat{\beta}_j(\lambda) = \frac{1}{\lambda + n_j} \sum_{i=1}^{n_i} \left(Y_{i,j} - \mu - \alpha_i\right)
$$

where $n_j$ is the number of ratings made for movie $j$. 

This approach will have our desired effect: when our sample size $n_j$ is very large, we obtain a stable estimate and the penalty $\lambda$ is effectively ignored since $n_j+\lambda \approx n_j$. Yet when the $n_j$ is small, then the estimate $\hat{\beta}_i(\lambda)$ is shrunken towards 0. The larger the $\lambda$, the more we shrink[@IDS2_23-6].

We will implement the _Regularization_ method on our  models (starting from the current model) in two steps:

  1. **Preconfiguration:** Preliminary determination of the optimal range of $\lambda$ values for the `5-Fold Cross Validation` samples;
  
  2. **Fine-tuning:** figuring out the value of $\lambda$ that minimizes the model's RMSE.


#### Regularization: Common Helper Functions
\

::: {.noteblock data-latex=""}
The full source code of the functions described below are available in the [Model Tuning](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/common-helper.functions.R#L74) section of the [common-helper.functions.R](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/common-helper.functions.R) script on _GitHub_.
:::

##### [tune.model_param](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/common-helper.functions.R#L116) Function {#func.tune.model_param}
\

The function searches for the parameter value corresponding to the minimum value of the `RMSE` from the list of values specified by the `param_values` parameter.

###### Sugnature
\
```{r eval=FALSE}
tune.model_param <- function(param_values, 
                             fn_tune.test.param_value, 
                             break.if_min = TRUE,
                             steps.beyond_min = 2){

# ...
  list(tuned.result = data.frame(RMSE = RMSEs_tmp,
                                parameter.value = param_vals_tmp),
       best_result = param_values.best_result)
}  
```

###### Parameters
\

  - **param_values:** A list of values to search for the value corresponding to the minimum value of the `RMSE` ; 
  - **fn_tune.test.param_value:** A helper function that calculates the value of the `RMSE` for a given parameter value.; 
  - **break.if_min = TRUE:** A Boolean parameter that determines whether the function should terminate after completing the number of steps specified by the parameter `steps.beyond_min`, after the minimum value of the `RMSE` has been found;
  - **steps.beyond_min = 2:** (takes effect only if `break.if_min` parameter is `TRUE`) Specifies the number of steps after finding the minimum value of the `RMSE`, upon completion of which the function should terminate.

###### Details
\
During execution, the function uses a helper function specified by the `fn_tune.test.param_value` parameter, which calculates the `RMSE` value for the given parameter from the list determined by the `param_values` parameter.

::: {.noteblock data-latex=""}
Note that the algorithm assumes that the dependence of the `RMSE` on the input parameter is a monotonically decreasing function until a minimum is reached and monotonically increasing thereafter. That is, it is assumed that the function has a single minimum on the given interval.
:::

###### Value
\
The function returns a data structure containing the found value of the input parameter `param_values` for which the `RMSE` value is minimal, as well as the minimum `RMSE` value itself, along with a sequence of all calculated `RMSE` values.

###### Source Code
\
Below is the most significant part of the code of the [tune.model_param](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/common-helper.functions.R#L116) function:
```{r eval=FALSE}
tune.model_param <- function(param_values, 
                             fn_tune.test.param_value, 
                             break.if_min = TRUE,
                             steps.beyond_min = 2){
  n <- length(param_values)
  param_vals_tmp <- numeric()
  RMSEs_tmp <- numeric()
  RMSE_min <- Inf
  i_max.beyond_RMSE_min <- Inf
  prm_val.best <- NA

  # ...
  
  for (i in 1:n) {
    put_log1("Function: `tune.model_param`:
Iteration %1", i)
    prm_val <- param_values[i]
    param_vals_tmp[i] <- prm_val
    
    RMSE_tmp <- fn_tune.test.param_value(prm_val)
    RMSEs_tmp[i] <- RMSE_tmp

    plot(param_vals_tmp[RMSEs_tmp], RMSEs_tmp[RMSEs_tmp])

    if(RMSE_tmp > RMSE_min){
      warning("Function: `tune.model_param`:
`RSME` reached its minimum: ", RMSE_min, "
for parameter value: ", prm_val)
      put_log2("Function: `tune.model_param`:
Current `RMSE` value is %1 related to parameter value: %2",
               RMSE_tmp,
               prm_val)
      
      if (i > i_max.beyond_RMSE_min) {
        warning("Function: `tune.model_param`:
Operation is breaked (after `RSME` reached its minimum) on the following step: ", i)
        break
      }
      next
    }

    RMSE_min <- RMSE_tmp
    prm_val.best <- prm_val
    
    if (break.if_min) {
      i_max.beyond_RMSE_min <- i + steps.beyond_min
    }
  }
  
  param_values.best_result <- c(param.best_value = prm_val.best, 
                                best_RMSE = RMSE_min)
  
  
  list(tuned.result = data.frame(RMSE = RMSEs_tmp,
                                parameter.value = param_vals_tmp),
       best_result = param_values.best_result)
}

```


##### [model.tune.param_range](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/common-helper.functions.R#L198) Function {#func.model.tune.param_range}
\

The function fine-tunes the model by searching for the best possible value of the input parameter over a given interval for which the corresponding `RMSE` value is minimal.

###### Sugnature
\
```{r eval=FALSE}
model.tune.param_range <- function(loop_starter,
                             tune_dir_path,
                             cache_file_base_name,
                             fn_tune.test.param_value,
                             max.identical.min_RMSE.count = 4,
                             endpoint.min_diff = 0,
                             break.if_min = TRUE,
                             steps.beyond_min = 2){
  # ...
  list(best_result = param_values.best_result,
       param_values.endpoints = c(prm_val.leftmost, prm_val.rightmost, seq_increment),
       tuned.result = data.frame(parameter.value = parameter.value,
                                 RMSE = result.RMSE))
}
```

###### Parameters
\

####### loop_starter 
\
A numeric vector of the form `c(start, end, dvs)`, where `start` and `end` are the endpoints of the interval on which the parameter value that minimizes `RMSE` is sought.
`dvs` is a divisor for splitting the interval to transform it into a sequence of values among which the value that minimizes `RMSE` is sought.
For this purpose, the sequence step is calculated as follows:
$$
step = \frac{end - start}{dvs}
$$  

The sequence obtained as a result of the transformation is equivalent to the one generated by the function `seq` as follows:
```{r eval=FALSE}
seq(start, end, step)
```  
In fact, the `seq` function is called internally to generate the sequence during the execution of the `model.tune.param_range` function.

####### tune_dir_path 
\
To improve performance, the algorithm caches intermediate results in the file system. This parameter specifies the path to the directory where the files are cached.

####### cache_file_base_name 
\
The algorithm generates unique names for cache files based on this and the `loop_starter` parameter, as well as some other intermediate values calculated during the execution.

#######  fn_tune.test.param_value
\
This is a helper function name that is passed to the same-named parameter of the [tune.model_param](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/common-helper.functions.R#L116) function that is called internally during the execution (see the description of the `tune.model_param` function [above](#func.tune.model_param)). 

####### max.identical.min_RMSE.count = 4
\
If more than one identical minimum `RMSE` value is calculated during execution, the number of identical minimums is limited by the value of this parameter. When it is reached, the algorithm considers the task execution to be complete.

####### endpoint.min_diff = 0
\
Defines the sensitivity threshold for determining the neighborhood boundaries of the minimum `RMSE` value (for details, see the `Details` section [below](#func.model.tune.param_range.details)).

####### break.if_min = TRUE 
\
This is a parameter that is required for the [tune.model_param](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/common-helper.functions.R#L116) function that is called internally during execution (see the description of the `tune.model_param` function [above](#func.tune.model_param)). 

####### steps.beyond_min = 2 
\
This is a parameter that is required for the [tune.model_param](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/common-helper.functions.R#L116) function that is called internally during execution (see the description of the `tune.model_param` function [above](#func.tune.model_param)). 

::: { #func.model.tune.param_range.details .sidebar }
***Details***

During execution, the function uses a helper function specified by the `fn_tune.test.param_value` parameter, which calculates the `RMSE` value for the given parameter from the list determined by the inner `param_values` sequence.
:::


###### **Value**
\


See the `func.model.tune.param_range` Function description [above](#func.model.tune.param_range). 


::: {.noteblock data-latex=""}
Note 
:::


###### Source Code
\
Below is the simplified version of the code of the [model.tune.param_range](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/common-helper.functions.R#L198) function:
```{r eval=FALSE}
model.tune.param_range <- function(loop_starter,
                             tune_dir_path,
                             cache_file_base_name,
                             fn_tune.test.param_value,
                             max.identical.min_RMSE.count = 4,
                             is.cv = TRUE,
                             endpoint.min_diff = 0, #1e-07,
                             break.if_min = TRUE,
                             steps.beyond_min = 2){

  seq_start <- loop_starter[1]
  seq_end <- loop_starter[2]
  range_divider <- loop_starter[3]
  
  if (range_divider < 4) {
    range_divider <- 4
  }
  
  prm_val.leftmost <- seq_start
  prm_val.rightmost <- seq_end
  
  RMSE.leftmost <- NA
  RMSE.rightmost <- NA

  best_RMSE <- NA
  param.best_value <- 0
  
  
  param_values.best_result <- c(param.best_value = param.best_value, 
                                best_RMSE = best_RMSE)
  # Start repeat loop
  repeat{
    seq_increment <- (seq_end - seq_start)/range_divider 
    
    if (seq_increment < 0.0000000000001) {
      warning("Function `model.tune.param_range`:
parameter value increment is too small.")
      break
    }
    
    test_param_vals <- seq(seq_start, seq_end, seq_increment)
    
    tuned_result <- tune.model_param(test_param_vals, 
                                  fn_tune.test.param_value,
                                  break.if_min,
                                  steps.beyond_min)
    
    tuned.result <- tuned_result$tuned.result
    plot(tuned.result$parameter.value, tuned.result$RMSE)
    
    bound.idx <- get_fine_tune.param.endpoints.idx(tuned.result)
    start.idx <- bound.idx["start"]
    end.idx <- bound.idx["end"]
    best_RMSE.idx <- bound.idx["best"]
    
    prm_val.leftmost.tmp <- tuned.result$parameter.value[start.idx]
    RMSE.leftmost.tmp <- tuned.result$RMSE[start.idx]

    prm_val.rightmost.tmp <- tuned.result$parameter.value[end.idx]
    RMSE.rightmost.tmp <- tuned.result$RMSE[end.idx]
    
    min_RMSE <- tuned.result$RMSE[best_RMSE.idx]
    min_RMSE.prm_val <- tuned.result$parameter.value[best_RMSE.idx]

    seq_start <- prm_val.leftmost.tmp
    seq_end <- prm_val.rightmost.tmp
    
    if (is.na(best_RMSE)) {
      prm_val.leftmost <- prm_val.leftmost.tmp
      RMSE.leftmost <- RMSE.leftmost.tmp
      
      prm_val.rightmost <- prm_val.rightmost.tmp
      RMSE.rightmost <- RMSE.rightmost.tmp
      
      param.best_value <- min_RMSE.prm_val
      best_RMSE <- min_RMSE
    }
    
    if (RMSE.leftmost.tmp - min_RMSE >= endpoint.min_diff) {
      prm_val.leftmost <- prm_val.leftmost.tmp
      RMSE.leftmost <- RMSE.leftmost.tmp
    } 
    
    if (RMSE.rightmost.tmp - min_RMSE >= endpoint.min_diff) {
      prm_val.rightmost <- prm_val.rightmost.tmp
      RMSE.rightmost <- RMSE.rightmost.tmp
    } 
    
    if (end.idx - start.idx <= 0) {
      warning("`tuned.result$parameter.value` sequential start index are the same or greater than end one.")
      break
    }
    
    if (best_RMSE == min_RMSE) {
      warning("Currently computed minimal RMSE equals the previously reached best one: ",
              best_RMSE, "
Currently computed minial value is: ", min_RMSE)

      if (sum(tuned.result$RMSE[tuned.result$RMSE == min_RMSE]) >= max.identical.min_RMSE.count) {
        warning("Minimal `RMSE`identical values count reached it maximum allowed value: ",
                max.identical.min_RMSE.count)

        param_values.best_result <-
          get_best_param.result(tuned.result$parameter.value,
                                tuned.result$RMSE)
        break
      }

    } else if (best_RMSE < min_RMSE) {
      stop("Current minimal RMSE is greater than previously computed best value: ",
           best_RMSE, "
Currently computed minial value is: ", min_RMSE)
    }

    best_RMSE <- min_RMSE
    param.best_value <- min_RMSE.prm_val

    param_values.best_result <- 
      get_best_param.result(tuned.result$parameter.value, 
                          tuned.result$RMSE)
  }
  # End repeat loop
  
  n <- length(tuned.result$parameter.value)
  parameter.value <- tuned.result$parameter.value
  result.RMSE <- tuned.result$RMSE
  
  if (result.RMSE[1] == best_RMSE) {
    parameter.value[1] <- prm_val.leftmost
    result.RMSE[1] <- RMSE.leftmost
  }
  if (result.RMSE[n] == best_RMSE) {
    parameter.value[n+1] <- prm_val.rightmost
    result.RMSE[n+1] <- RMSE.rightmost
    # browser()
  }
  
  list(best_result = param_values.best_result,
       param_values.endpoints = c(prm_val.leftmost, prm_val.rightmost, seq_increment),
       tuned.result = data.frame(parameter.value = parameter.value,
                                 RMSE = result.RMSE))
}
```

::: {.noteblock data-latex=""}
The full version of the code of the [model.tune.param_range](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/common-helper.functions.R#L198) is available in the [Model Tuning](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/common-helper.functions.R#L74) section of the [common-helper.functions.R](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/support-functions/common-helper.functions.R#L198) script.
:::


##### `` Function
\

See the `Details`section [above](#func.model.tune.param_range.details).

See the `Details`section above \@ref(sec:func.model.tune.param_range.details)


###### Sugnature
\
```{r eval=FALSE}

```

###### Parameters
\
  - **fn_tune.test.param_value:** A helper function that calculates the value of the `RMSE` for a given parameter value.; 
  - **break.if_min = TRUE:** A Boolean parameter that determines whether the function should terminate after completing the number of steps specified by the parameter `steps.beyond_min`, after the minimum value of the `RMSE` has been found;
  - **steps.beyond_min = 2:** (takes effect only if `break.if_min` parameter is `TRUE`) Specifies the number of steps after finding the minimum value of the `RMSE`, upon completion of which the function should terminate.

###### Details
\
During execution, the function uses a helper function specified by the `fn_tune.test.param_value` parameter, which calculates the `RMSE` value for the given parameter from the list determined by the `param_values` parameter.

::: {.noteblock data-latex=""}
Note 
:::

###### Value
\


###### Source Code
\
Below is the most significant part of the code of the [function]() function:
```{r eval=FALSE}

```


##### `` Function
\


###### Sugnature
\
```{r eval=FALSE}

```

###### Parameters
\
  - **fn_tune.test.param_value:** A helper function that calculates the value of the `RMSE` for a given parameter value.; 
  - **break.if_min = TRUE:** A Boolean parameter that determines whether the function should terminate after completing the number of steps specified by the parameter `steps.beyond_min`, after the minimum value of the `RMSE` has been found;
  - **steps.beyond_min = 2:** (takes effect only if `break.if_min` parameter is `TRUE`) Specifies the number of steps after finding the minimum value of the `RMSE`, upon completion of which the function should terminate.

###### Details
\
During execution, the function uses a helper function specified by the `fn_tune.test.param_value` parameter, which calculates the `RMSE` value for the given parameter from the list determined by the `param_values` parameter.

::: {.noteblock data-latex=""}
Note 
:::

###### Value
\


###### Source Code
\
Below is the most significant part of the code of the [function]() function:
```{r eval=FALSE}

```





```{r eval=FALSE}

```
::: {.noteblock data-latex=""}
!!! Note!
:::


```{r eval=FALSE}

```

```{r eval=FALSE}

```

##### `` Function
\



###### Sugnature
\
```{r eval=FALSE}

```

###### Parameters
\
  - **fn_tune.test.param_value:** A helper function that calculates the value of the `RMSE` for a given parameter value.; 
  - **break.if_min = TRUE:** A Boolean parameter that determines whether the function should terminate after completing the number of steps specified by the parameter `steps.beyond_min`, after the minimum value of the `RMSE` has been found;
  - **steps.beyond_min = 2:** (takes effect only if `break.if_min` parameter is `TRUE`) Specifies the number of steps after finding the minimum value of the `RMSE`, upon completion of which the function should terminate.

###### Details
\
During execution, the function uses a helper function specified by the `fn_tune.test.param_value` parameter, which calculates the `RMSE` value for the given parameter from the list determined by the `param_values` parameter.

::: {.noteblock data-latex=""}
Note 
:::

###### Value
\


###### Source Code
\
Below is the most significant part of the code of the [function]() function:
```{r eval=FALSE}

```



```{r eval=FALSE}

```

::: {.noteblock data-latex=""}
!!! Note!
:::

::: {.noteblock data-latex=""}
!!! Note!
:::

::: {.noteblock data-latex=""}
!!! Note!
:::



```{r eval=FALSE}

```

```{r eval=FALSE}

```

##### `` Function
\



###### Sugnature
\
```{r eval=FALSE}

```

###### Parameters
\
  - **fn_tune.test.param_value:** A helper function that calculates the value of the `RMSE` for a given parameter value.; 
  - **break.if_min = TRUE:** A Boolean parameter that determines whether the function should terminate after completing the number of steps specified by the parameter `steps.beyond_min`, after the minimum value of the `RMSE` has been found;
  - **steps.beyond_min = 2:** (takes effect only if `break.if_min` parameter is `TRUE`) Specifies the number of steps after finding the minimum value of the `RMSE`, upon completion of which the function should terminate.

###### Details
\
During execution, the function uses a helper function specified by the `fn_tune.test.param_value` parameter, which calculates the `RMSE` value for the given parameter from the list determined by the `param_values` parameter.

::: {.noteblock data-latex=""}
Note 
:::

###### Value
\


###### Source Code
\
Below is the most significant part of the code of the [function]() function:
```{r eval=FALSE}

```



```{r eval=FALSE}

```


```{r eval=FALSE}

```

```{r eval=FALSE}

```


#### UME Model Regularization: Support Function
\

::: {.noteblock data-latex=""}
The [regularize.test_lambda.UM_effect.cv]() function described below are defined in the [Regularization]() section of the [UM-effect.functions.R]() script.
:::

##### `regularize.test_lambda.UM_effect.cv` Function
\

This function calculates _RMSE_ of the _UME Model_ using _5-Fold CV_ method for the given $\lambda$ parameter value:
```{r eval=FALSE}
regularize.test_lambda.UM_effect.cv <- function(lambda){
  if (is.na(lambda)) {
    stop("Function: regularize.test_lambda.UM_effect.cv
`lambda` is `NA`")
  }
  um_effect <- train_user_movie_effect.cv(lambda)
  calc_user_movie_effect_RMSE.cv(um_effect)
}
```

::: {.noteblock data-latex=""}
Note that we reuse the function [train_user_movie_effect.cv]() calling it from the [regularize.test_lambda.UM_effect.cv](), but now with the $\lambda$ parameter different from the default (zero) value.
:::

Let's now figure out the $\lambda$ that minimizes the _RMSE_:
```{r eval=FALSE}
# Here we will simply compute the RMSE for different values of `lambda` 
n <- colSums(!is.na(y))

sums <- colSums(y - mu - a, na.rm = TRUE)
lambdas <- seq(0, 10, 0.1)

rmses <- sapply(lambdas, function(lambda){
  b <-  sums / (n + lambda)
  reg_rmse(b)
})

# Here is a plot of the RMSE versus `lambda`:
plot(lambdas, rmses, type = "l")
```
Now we can determine the minimal _RMSE_:
```{r}
# print(min(rmses))
```

which is achieved for the following $\lambda$:
```{r eval=FALSE}
lambda <- lambdas[which.min(rmses)] 
print(lambda)
```

Using this $\lambda$ we can compute the regularized estimates:
```{r eval=FALSE}
b_reg <- sums / (n + lambda)

str(b_reg)
```
Finally, let's verify that the penalized estimates $\hat{b}_i(\lambda)$ we have just computed actually result in the minimal _RMSE_ figured out above: 
```{r eval=FALSE}
reg_rmse(b_reg)
```








### Accounting for Date effects


##### Yearly rating count[@MRS-R-BEST]
\
```{r}
print(edx |> 
  mutate(year = year(as_datetime(timestamp, origin = "1970-01-01"))) |>
  group_by(year) |>
  summarize(count = n())
)
```

##### Average rating per year plot[@MRS-R-BEST]
\
```{r}
edx |> 
  mutate(year = year(as_datetime(timestamp, origin = "1970-01-01"))) |>
  group_by(year) |>
  summarize(rating_avg = mean(rating)) |>
  ggplot(aes(x = year, y = rating_avg)) +
  geom_bar(stat = "identity", fill = "#8888ff") + 
  ggtitle("Average rating per year") +
  xlab("Year") +
  ylab("Average rating") +
  scale_y_continuous(labels = comma) + 
  theme_economist() +
  theme(axis.title.x = element_text(vjust = -5, face = "bold"), 
        axis.title.y = element_text(vjust = 10, face = "bold"), 
        plot.margin = margin(0.7, 0.5, 1, 1.2, "cm"))
```

We use the following models to account for the `date` effect:

$$
Y_{i,j} = \mu + \alpha_i + \beta_j + f(d_{i,j}) + \varepsilon_{i,j}
$$

### Accounting for Genre effect
\
As mentioned in [Section 23.7: Exercises](https://rafalab.dfci.harvard.edu/dsbook-part-2/highdim/regularization.html#exercises) of the _Chapter "23 Regularization" of the Course Textbook_ the `Movielens` dataset also has a genres column. This column includes every genre that applies to the movie (some movies fall under several genres)[@IDS2_23-7].

#### Genre Data Analysis
\
##### Movie Genres Data 
\
The following code computes movie rating summaries by popular genres like Drama, Comedy, Thriller, and Romance:
```{r eval=FALSE}
#library(stringr)
genres = c("Drama", "Comedy", "Thriller", "Romance")
sapply(genres, function(g) {
  sum(str_detect(edx$genres, g))
})
```

Further, we can find out the movies that have the greatest number of ratings using the following code:
```{r eval=FALSE}
ordered_movie_ratings <- edx |> group_by(movieId, title) |>
  summarize(number_of_ratings = n()) |>
  arrange(desc(number_of_ratings))
print(head(ordered_movie_ratings))
```

and figure out the most given ratings in order from most to least:
```{r eval=FALSE}
ratings <- edx |>  group_by(rating) |>
     summarise(count = n()) |>
     arrange(desc(count))
print(ratings)
```

The following code allows us to summarize that in general, half-star ratings are less common than whole-star ratings (e.g., there are fewer ratings of 3.5 than there are ratings of 3 or 4, etc.):
```{r eval=FALSE}
print(edx |> group_by(rating) |> summarize(count = n()))
```

We can visually see that from the following plot:
```{r eval=FALSE}
edx |>
  group_by(rating) |>
  summarize(count = n()) |>
  ggplot(aes(x = rating, y = count)) +
  geom_line() 

```

##### Movie Genres Effect 
\


The plot below shows strong evidence of a genre effect (for illustrative purposes, the plot shows only categories with more than 20, 000 ratings).

```{r eval=FALSE}
# Preparing data for plotting:
genre_ratins_grp <- train_set |> 
  mutate(genre_categories = as.factor(genres)) |>
  group_by(genre_categories) |>
  summarize(n = n(), rating_avg = mean(rating), se = sd(rating)/sqrt(n())) |>
  filter(n > 20000) |> 
  mutate(genres = reorder(genre_categories, rating_avg)) |>
  select(genres, rating_avg, se, n)

dim(genre_ratins_grp)
genre_ratins_grp_sorted <- genre_ratins_grp |> sort_by.data.frame(~ rating_avg)
print(genre_ratins_grp_sorted)

# Creating plot:
genre_ratins_grp |> 
  ggplot(aes(x = genres, y = rating_avg, ymin = rating_avg - 2*se, ymax = rating_avg + 2*se)) + 
  geom_point() +
  geom_errorbar() + 
  ggtitle("Average rating per Genre") +
  ylab("Average rating") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```
Below are worst and best ratings categories:
```{r eval=FALSE}
sprintf("The worst ratings are for the genre category: %s",
        genre_ratins_grp$genres[which.min(genre_ratins_grp$genres)])

sprintf("The best ratings are for the genre category: %s",
        genre_ratins_grp$genres[which.max(genre_ratins_grp$genres)])
```

Another way of visualizing a genre effect is shown in the section [Average rating for each genre](https://www.kaggle.com/code/amirmotefaker/movie-recommendation-system-using-r-best/notebook#Average-rating-for-each-genre) of the article "Movie Recommendation System using R - BEST" written by [Amir Moterfaker](https://www.kaggle.com/amirmotefaker)[@MRS-R-BEST]:
```{r eval=FALSE}
# For better visibility, we reduce the data for plotting 
# while keeping the worst and best rating rows:
plot_ind <- odd(1:nrow(genre_ratins_grp))
plot_dat <- genre_ratins_grp_sorted[plot_ind,] 

plot_dat |>
  ggplot(aes(x = rating_avg, y = genres)) +
  ggtitle("Genre Average Rating") +
  geom_bar(stat = "identity", width = 0.6, fill = "#8888ff") +
  xlab("Average ratings") +
  ylab("Genres") +
  scale_x_continuous(labels = comma, limits = c(0.0, 5.0)) +
  theme_economist() +
  theme(plot.title = element_text(vjust = 3.5),
        axis.title.x = element_text(vjust = -5, face = "bold"),
        axis.title.y = element_text(vjust = 10, face = "bold"),
        axis.text.x = element_text(vjust = 1, hjust = 1, angle = 0),
        axis.text.y = element_text(vjust = 0.25, hjust = 1, size = 8),
        plot.margin = margin(0.7, 0.5, 1, 1.2, "cm"))
```

If we define $g_{i,j}$ as the genre for user's $i$ rating of movie $j$, we can use the following models to account for the `genre` effect:

To account for _genre effects_ we will use the model suggested in the [Section 23.7: Exercises](https://rafalab.dfci.harvard.edu/dsbook-part-2/highdim/regularization.html#exercises) of the _Chapter "23 Regularization" of the Course Textbook_[@IDS2_23-7]:

$$
Y_{i,j} = \mu + \alpha_i + \beta_j + g_{i,j} + \varepsilon_{i,j}
$$

where $g_{i,j}$ is an _aggregation function_ which is explained in detail in _Section 22.3: "Review of Aggregation Functions" of "Recommender Systems Handbook"_ (_Chapter 22: "Aggregation of Preferences in Recommender Systems"_, p. 712) book[@RRSK_RS_HB].

In the formula above $g_{i,j}$ denotes a _genre effect_ for user's $i$ rating of movie $j$, so that:

$$
g_{i,j} = \sum_{k=1}^K x_{i,j}^k \gamma_k
$$

with $x^k_{i,j} = 1$ if $g_{i,j}$ includes genre $k$, and $x^k_{i,j} = 0$ otherwise.



$$
Y_{i,j} = \mu + \alpha_i + \beta_j + g_{i,j} + f(d_{i,j})
$$


$$
 \sum_{i=1}^{n_i} \left(Y_{i,j} - \mu - \alpha_i\right)
$$


## Conclusion

Hello Conclusion!

This is a great conclusion, isn't it?!!
