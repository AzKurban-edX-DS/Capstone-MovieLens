## User+Movie+Genre Effect (UMGE) Model
\

As we can see from the `edx` dataset structure, the `Movielens` dataset also has a genres column. This column includes every genre that applies to the movie (some movies fall under several genres):
```{r}
str(edx)
```

### Movie Genres Effect Anasysis
\

The plot below shows strong evidence of a genre effect (for illustrative purposes, the plot shows only categories with more than 40, 000 ratings).

```{r }
# Preparing data for plotting:
genre_ratins_grp <- edx |> 
  mutate(genre_categories = as.factor(genres)) |>
  group_by(genre_categories) |>
  summarize(n = n(), rating_avg = mean(rating), se = sd(rating)/sqrt(n())) |>
  filter(n > 40000) |> 
  mutate(genres = reorder(genre_categories, rating_avg)) |>
  select(genres, rating_avg, se, n)

# Creating plot:
genre_ratins_grp |> 
  ggplot(aes(x = genres, y = rating_avg, ymin = rating_avg - 2*se, ymax = rating_avg + 2*se)) + 
  geom_point() +
  geom_errorbar() + 
  ggtitle("Average rating per Genre") +
  ylab("Average rating") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Below are worst and best ratings categories:
```{r, echo=FALSE}
sprintf("The worst ratings are for the genre category: %s",
        genre_ratins_grp$genres[which.min(genre_ratins_grp$genres)])

sprintf("The best ratings are for the genre category: %s",
        genre_ratins_grp$genres[which.max(genre_ratins_grp$genres)])
```

### Mathematical Description of the UMGE Model
\

If we define a _genre treatment effect_ $g_{i,j}$ for user's $i$ rating of movie $j$, we can use the following models to account for the `genre` effect:

\begin{equation}
Y_{i,j} = \mu + \alpha_i + \beta_j + g_{i,j} + \varepsilon_{i,j}
(\#eq:UMGE-model)
\end{equation}

where $g_{i,j}$ is an _aggregation function_ which is explained in detail in _Section 22.3: "Review of Aggregation Functions" of "Recommender Systems Handbook"_ (_Chapter 22: "Aggregation of Preferences in Recommender Systems"_, p. 712) book[@RRSK_RS_HB].

In the formula above $g_{i,j}$ denotes a _genre effect_ for user's $i$ rating of movie $j$, so that:

$$
g_{i,j} = \sum_{k=1}^K x_{i,j}^k \gamma_k
$$

with $x^k_{i,j} = 1$ if $g_{i,j}$ includes genre $k$, and $x^k_{i,j} = 0$ otherwise.

Therefore, for our current model, we can compute a predicted value 
$$
\hat{g}_{i,j} = g_{i,j} + \varepsilon_{i,j}
$$
as a residual: 


\begin{equation}
\hat{g}_{i,j} = Y_{i,j} - (\mu + \alpha_i + \beta_j)
(\#eq:genre-effect)
\end{equation}


### UMGE Model Building
\

::: {.noteblock data-latex=""}
The complete source code of builing and training the current model is available in the [UMGE Model Building](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R#L878) section of the [capstone-movielens.main.R](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R#L878) script on _GitHub_.
:::

Below, we provide the most significant part of the code for training our model using the `5-Fold Cross Validation` method:
```{r, fn.train_user_movie_genre_effect.cv,   eval=FALSE}
cv.UMG_effect <- train_user_movie_genre_effect.cv()
```

::: {.noteblock data-latex=""}
In the code snippet above we use the [train_user_movie_genre_effect.cv](#func.train_user_movie_genre_effect.cv) function described in the *Models Training: Support Functions /* [UMGE Model: Utility Functions] section of [Appendix A: Support Functions].
:::


```{r, hist.cv.UMG_effect }
str(cv.UMG_effect)
  
par(cex = 0.7)
hist(cv.UMG_effect$g, 30, xlab = TeX(r'[$\hat{g}_{i,j}$]'),
     main = TeX(r'[Histogram of $\hat{g}_{i,j}$]'))
```

\newpage

We can now construct predictors and calculate the _RMSE_ of the *UMGE Model* using the
following code:
```{r, eval=FALSE}
cv.UMG_effect.RMSE <- calc_user_movie_genre_effect_RMSE.cv(cv.UMG_effect)

RMSEs.ResultTibble.UMGE <- RMSEs.ResultTibble.rglr.UME |> 
  RMSEs.AddRow("User+Movie+Genre Effect (UMGE) Model", cv.UMG_effect.RMSE)
```
```{r}
RMSE_kable(RMSEs.ResultTibble.UMGE)
```

::: {.noteblock data-latex=""}
In the code snippet above, we use the following functions described in [Appendix A: Support Functions]: 

  - [calc_user_movie_genre_effect_RMSE.cv](#func.calc_user_movie_genre_effect_RMSE.cv) (described in the *Models Training: Support Functions /* [UMGE Model: Utility Functions] section) to calculate the *RMSE* for the *UMGE Model*;
  
  - [RMSEs.AddRow](#func.RMSEs.AddRow) and [RMSE_kable](#func.RMSE_kable) (described in the *Common Helper Functions /* [Result RMSEs Tibble Functions] section) to update and print the table above.
:::

Unfortunately, for some reason, we do not see any improvement here yet.

\newpage

### UMGE Model Regularization
\

We have already explained the idea of the _Linear Model Regularization_ in the [UME Model Regularization] section above. Let's extend the concept outlined there to our current model.

In this case, the formula \@ref(eq:ME-penalty) for adding a penalty takes the form:

\begin{equation}
\sum_{i,j} \left(y_{u,i} - \mu - \alpha_i - \beta_j - g_{i,j}\right)^2 + \lambda \sum_{i,j} g_{i,j}^2
(\#eq:GE-penalty)
\end{equation}

And the formula \@ref(eq:ME-regularized) for calculating the values of the _treatment effect_ that minimizes the equation will take the form:

\begin{equation}
\hat{g}_{i,j}(\lambda) = \frac{1}{\lambda + n_g} \sum_{r=1}^{n_{g}} \left(Y_{i,j} - \mu - \alpha_i - \beta_j\right)
(\#eq:GE-regularized)
\end{equation}

where $n_{g}$ is the number of ratings made for genre $g$. 

As we decided earlier (and outlined in the [UME Model Regularization] section), we implement the *Regularization method* for our models in the following three steps:

  1. **Pre-configuration:** Preliminary determination of the optimal range of *regularization parameter* $\lambda$ values for the *K-Fold Cross-Validation* samples;
  
  2. **Fine-tuning:** Figuring out the best value of $\lambda$ with the highest possible accuracy that minimizes the *RMSE* of the model.

  3. **Retraining:** Retraining the model with the best value of $\lambda$ determined in the previous step.

\newpage

#### UMGE Model Regularization: Pre-configuration
\

::: {.noteblock data-latex=""}
The complete version of the source code provided in this section can be found in the [UMGE Model Regularization: Pre-configuration](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R#L961) section of the [capstone-movielens.main.R](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R#L961) script.
:::

As we explain earlier in the [UME Model Regularization: *Pre-configuration*], we need to do some pre-configuration to determine a suitable range of $\lambda$ for subsequent fine-tuning of our current model.

Below we provide the most significant part of the code that performs this operation:

::: {.noteblock data-latex=""}
The functions [tune.model_param](#func.tune.model_param) and [regularize.test_lambda.UMG_effect.cv](#func.regularize.test_lambda.UMG_effect.cv) are described in the sections *Common Helper Functions /* [ Regularization Functions](#appndx_a.CHF.regularization) and  *Models Training: Support Functions /* [UMGE Model: Regularization] of [Appendix A: Support Functions], respectively.
:::



Let's perform the preconfiguration to determine the appropriate range of $\lambda$ for subsequent fine-tuning of our current model:

We are going to use the [tune.model_param](#func.tune.model_param) function described in the [Common Helper Functions: Regularization](#appndx_a.CHF.regularization) section of [Appendix A: Support Functions], passing the [regularize.test_lambda.UMG_effect.cv](#func.regularize.test_lambda.UMG_effect.cv) function as the value of the [fn_tune.test.param_value](#func.tune.model_param.args.fn_tune.test.param_value) parameter.

Below we provide the most significant part of the code that performs this operation:
```{r, eval=FALSE}
lambdas <- seq(0, 0.2, 0.01)

cv.UMGE.preset.result <- 
  tune.model_param(lambdas, regularize.test_lambda.UMG_effect.cv)

put_log1("Preliminary regularization set-up of `lambda`s range for the UMGE Model has been completed
for the %1-Fold Cross Validation samples.",
CVFolds_N)
```
```{r}
str(cv.UMGE.preset.result)
cv.UMGE.preset.result$best_result
```

::: {.noteblock data-latex=""}
The custom functions [tune.model_param](#func.tune.model_param) and [regularize.test_lambda.UMG_effect.cv](#func.regularize.test_lambda.UMG_effect.cv) used in the code snippet above are described in the sections *Common Helper Functions /* [Regularization Functions](#appndx_a.CHF.regularization) and  *Models Training: Support Functions /* [UMGE Model: Regularization] of [Appendix A: Support Functions], respectively.
:::

Now, let's visualize the results of the $\lambda$ range preconfiguration:
``` {r}
cv.UMGE.preset.result$tuned.result |>
  data.plot(title = TeX(r'[UMGE Model Regularization: $\lambda$ Range Pre-configuration]'),
              xname = "parameter.value", 
              yname = "RMSE", 
              xlabel = TeX(r'[$\lambda$]'), 
              ylabel = str_glue("Deviation from the best RMSE value (",
                                as.character(round(cv.UMGE.preset.result$best_result["best_RMSE"], 
                                                   digits = 7)),
                                ")"),
              normalize = TRUE)
```

::: {.noteblock data-latex=""}
In the code snippet above, we use the custom data visualization function [data.plot](#func.data.plot) described in the *Data Helper Functions /* [Data Visualization Functions] section of [Appendix A: Support Functions].
:::

\newpage

#### UMGE Model Regularization: Fine-tuning
\

::: {.noteblock data-latex=""}
The complete version of the source code provided in this section can be found in the [UMGE Model Regularization: Fine-tuning](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R#L1019) section of the [capstone-movielens.main.R](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R#L1019) script on _GitHub_.
:::

We are now ready to perform the fine-tuning step of our model _regularization_ process to determine the best value for the $\lambda$ parameter.

Below we provide the most significant part of the code that performs this operation:
```{r, eval=FALSE}
endpoints <- 
  get_fine_tune.param.endpoints(cv.UMGE.preset.result$tuned.result)

UMG_effect.loop_starter <- c(endpoints["start"], 
                            endpoints["end"], 
                            8)
```

::: {.noteblock data-latex=""}
The helper function [get_fine_tune.param.endpoints](#func.get_fine_tune.param.endpoints) used in code snippet above is described in the sections *Common Helper Functions /* [ Regularization Functions](#appndx_a.CHF.regularization) of [Appendix A: Support Functions].
:::

```{r}
UMG_effect.loop_starter
UMGE.rglr.fine_tune.cache.path
```
```{r, eval=FALSE}
UMGE.rglr.fine_tune.cache.base_name <- "UMGE.rglr.fine-tuning"

UMGE.rglr.fine_tune.results <- 
  model.tune.param_range(UMG_effect.loop_starter,
                         UMGE.rglr.fine_tune.cache.path,
                         UMGE.rglr.fine_tune.cache.base_name,
                         regularize.test_lambda.UMG_effect.cv)

UMGE.rglr.fine_tune.RMSE.best <- UMGE.rglr.fine_tune.results$best_result["best_RMSE"]
```

::: {.noteblock data-latex=""}
The custom functions [model.tune.param_range](#func.model.tune.param_range) and [regularize.test_lambda.UM_effect.cv](#func.regularize.test_lambda.UM_effect.cv) used in the code snippet above are described in the sections *Common Helper Functions /* [Regularization Functions](#appndx_a.CHF.regularization) and  *Models Training: Support Functions /* [UME Model: Regularization] of [Appendix A: Support Functions], respectively.
:::

```{r, echo=FALSE}
writeLines("*** Fine-tuning results object data structure ***")
```
```{r}
str(UMGE.rglr.fine_tune.results)
```
```{r, echo=FALSE}
writeLines("*** Fine-tuning: best results ***")
```
```{r}
UMGE.rglr.fine_tune.results$best_result
UMGE.rglr.fine_tune.RMSE.best
```

Let's visualize the fine-tuning results:
```{r}
UMGE.rglr.fine_tune.results$tuned.result |>
  data.plot(title = "UMGE Model Regularization: Fine-tuned result",
              xname = "parameter.value",
              yname = "RMSE",
              xlabel = TeX(r'[$\lambda$]'),
              ylabel = str_glue("Deviation from the best RMSE value (",
                                as.character(round(UMGE.rglr.fine_tune.RMSE.best, digits = 7)),
                                ")"),
              normalize = TRUE)
```

::: {.noteblock data-latex=""}
Note that in the code snippet above, we use the custom data visualization function [data.plot](#func.data.plot) (described in the *Data Helper Functions /* [Data Visualization Functions] section of [Appendix A: Support Functions]) with the argument [normalize](#func.data.plot.args.normalize) set to `TRUE`, which means that the deviations from the mean of $y$ are used to plot, rather than the $y$ values themselves.
:::

\newpage

#### UMGE Model Regularization: Retraining Model with the best $\lambda$
\

Now, we can calculate the _Regularized UMG Effect_ by retraining our model on the entire `edx` dataset with the best value of the $\lambda$ parameter we just calculated, for the definitive _Root Mean Squared Error_ calculation and use in subsequent models.
```{r, eval=FALSE}
  best_result <- UMGE.rglr.fine_tune.results$best_result
  # param.best_value        best_RMSE 
  #     0.03554688       0.87297303 
  
  UMGE.rglr.best_lambda <- best_result["param.best_value"]
  UMGE.rglr.best_RMSE <- best_result["best_RMSE"]
  
  put_log1("Re-training Regularized User+Movie+Genre Effect Model for the best `lambda`: %1...",
           UMGE.rglr.best_lambda)
  
  rglr.UMG_effect <- edx.sgr |> train_user_movie_genre_effect(UMGE.rglr.best_lambda)
```
```{r}
str(rglr.UMG_effect)
```

::: {.noteblock data-latex=""}
The complete version of the source code provided in this section are available in the [Re-training Regularized UMG Effect Model for the best $\lambda$](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R#L910) section of the [capstone-movielens.main.R](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R#L910) script on _GitHub_.
:::

We calculate the _Root Mean Squared Error_ for the ultimately computed _UMG Effect_ using [calc_UMG_effect_RMSE.cv](#func.calc_UMG_effect_RMSE.cv) function described above as follows:
```{r, eval=FALSE}
  rglr.UMG_effect.RMSE <- calc_user_movie_genre_effect_RMSE.cv(rglr.UMG_effect)
```
```{r, echo=FALSE}
  print_log2("Regularized User+Movie+Genre Effect RMSE has been computed for the best `lambda = %1`: %2.",
           UMGE.rglr.best_lambda,
           rglr.UMG_effect.RMSE)
```

Finally, we add the definitive result for the current model to our _Result Table_:
```{r, eval=FALSE}
RMSEs.ResultTibble.rglr.UMGE <- RMSEs.ResultTibble.UMGE |> 
  RMSEs.AddRow("Regularized User+Movie+Genre Effect Model", 
               rglr.UMG_effect.RMSE,
               comment = "Computed for `lambda` = %1" |>
                 msg.glue(UMGE.rglr.best_lambda))
```
```{r}
RMSE_kable(RMSEs.ResultTibble.rglr.UMGE)
```

::: {.noteblock data-latex=""}
Here use the [RMSEs.AddRow](#func.RMSEs.AddRow) and [RMSE_kable](#func.RMSE_kable) functions described in the [Result RMSEs Tibble Functions] section of [Appendix A: Support Functions].
:::

As we can see, the current model still does not show much improvement after _regularization_, even though the data analysis we made in the [Movie Genres Effect] section showed strong evidence of a genre effect.
It looks like we need a better model to account for a genre effect more efficiently. 

Or, maybe, we have implemented the current model not quite correctly (?)

\newpage

