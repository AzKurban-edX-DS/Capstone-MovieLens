@string{hup     = {Harvard University Press}}
@string{crc     = {CRC Press}}

@online{MRS-R-BEST,
  author       = {Amir Motefaker},
  title        = {Movie Recommendation System using R - BEST},
  date         = {2024-07-18},
  version      = {284},
  url          = {https://www.kaggle.com/code/amirmotefaker/movie-recommendation-system-using-r-best/notebook},
  urldate      = {2025-02-18},
  langid       = {english},
  langidopts   = {variant=american},
  sorttitle    = {Movie Recommendation System using R - BEST},
  annotation   = {A movie recommendation system, or a movie recommender system, 
                  is an ML-based approach to filtering or predicting the users’ 
                  film preferences based on their past choices and behavior. 
                  It’s an advanced filtration mechanism that predicts the possible 
                  movie choices of the concerned user and their preferences towards 
                  a domain-specific item, aka movie.},
}

@online{edx_capstone_movielens_data,
  author       = {Azamat Kurbanaev},
  title        = {edX Data Science: Capstone, MovieLens Datasets},
  date         = {2025-02-05},
  url          = {https://github.com/AzKurban-edX-DS/edx.capstone.movielens.data},
  subtitle     = {Package: edx.capstone.movielens.data},
  version      = {0.0.0.9000},
  urldate      = {2025-02-05},
  langid       = {english},
  langidopts   = {variant=american},
  sorttitle    = {edX Data Science: Capstone, MovieLens Datasets},
  annotation   = {Provides datasets for MovieLens project of the edX HarvardX PH125.9x Data Science: Capstone course.},
}

@online{edx_capstone_movielens,
  author       = {Azamat Kurbanaev},
  title        = {edX Data Science: Capstone-MovieLens Project},
  date         = {2025-05-05},
  url          = {https://github.com/AzKurban-edX-DS/Capstone-MovieLens/tree/main},
  subtitle     = {A movie recommendation system using the MovieLens dataset},
  version      = {1.0.0.0},
  urldate      = {2025-05-05},
  langid       = {english},
  langidopts   = {variant=american},
  sorttitle    = {edX Data Science: Capstone, MovieLens Project},
  annotation   = {Contains Capstone, MovieLens project's code base.},
}

@online{chin_FPSGM_MF_SMS2015a,
  author       = {Wei-Sheng Ghin and Yong Zhuang and Yu-Chin Juan and Chih-Jen Lin.},
  title        = {A Fast Parallel Stochastic Gradient Method for Matrix Factorization in Shared Memory Systems},
  year         = {2015},
  url          = {https://www.csie.ntu.edu.tw/~cjlin/papers/libmf/libmf_journal.pdf},
  subtitle     = {ACM TIST 2015a},
  langid       = {english},
  langidopts   = {variant=american},
  annotation   = {In this paper, we develop a fast parallel SG method, FPSG, for shared
memory systems.},
}

@online{chin_LRS_SGM_MF2015b,
  author       = {Wei-Sheng Chin and Yong Zhuang and Yu-Chin Juan and Chih-Jen Lin},
  title        = {A Learning-Rate Schedule for Stochastic Gradient Methods to Matrix Factorization},
  year         = {2015},
  url          = {https://www.csie.ntu.edu.tw/~cjlin/papers/libmf/mf_adaptive_pakdd.pdf},
  subtitle     = {PAKDD 2015b},
  langid       = {english},
  langidopts   = {variant=american},
  annotation   = {In this paper, motivated from past works on convex optimization which assign
                  a learning rate for each variable, we propose a new schedule for matrix
                  factorization.},
}

@online{yqiu_recosystem230505,
  author       = {Yixuan Qiu},
  title        = {recosystem: Recommender System Using Parallel Matrix Factorization},
  date         = {2023-05-05},
  url          = {https://cran.r-project.org/web/packages/recosystem/vignettes/introduction.html},
  urldate      = {2023-05-05},
  langid       = {english},
  langidopts   = {variant=american},
  sorttitle    = {recosystem: Recommender System Using Parallel Matrix Factorization},
  annotation   = {`recosystem` is an R wrapper of the LIBMF library developed by 
                  Yu-Chin Juan, Wei-Sheng Chin, Yong Zhuang, Bo-Wen Yuan, Meng-Yuan Yang, 
                  and Chih-Jen Lin, an open source library for recommender system 
                  using parallel marix factorization},
}

@book{IDS_E1,
  author       = {Rafael A. Irizarry},
  title        = {Introduction to Data Science, First Edition},
  date         = {2019-10-24},
  url          = {https://rafalab.dfci.harvard.edu/dsbook/preface-for-first-edition.html},
  subtitle     = {Data Analysis and Prediction Algorithms with R},
  urldate      = {2019-10-24},
  langid       = {english},
  langidopts   = {variant=american},
  sorttitle    = {Data Analysis and Prediction Algorithms with R},
  annotation   = {This book started out as the class notes used in the HarvardX 
                  Data Science Series.},
}

@book{IDS_E1_33,
  author       = {Rafael A. Irizarry},
  title        = {Introduction to Data Science, First Edition, Chapter 33: Large datasets},
  date         = {2019-10-24},
  url          = {https://rafalab.dfci.harvard.edu/dsbook/large-datasets.html},
  subtitle     = {Data Analysis and Prediction Algorithms with R},
  urldate      = {2019-10-24},
  langid       = {english},
  langidopts   = {variant=american},
  annotation   = {In this chapter we scratch the surface of a variety of computational techniques 
                  and statistical concepts that are useful for the analysis of large datasets 
                  by describing matrix algebra, dimension reduction, regularization, and matrix factorization.},
}

@book{IDS_E1_33-7-1,
  author       = {Rafael A. Irizarry},
  title        = {Introduction to Data Science, First Edition, Chapter 33: Large datasets, Section 33.7.1: Movilens data},
  date         = {2019-10-24},
  url          = {https://rafalab.dfci.harvard.edu/dsbook/large-datasets.html#movielens-data},
  subtitle     = {Data Analysis and Prediction Algorithms with R},
  urldate      = {2019-10-24},
  langid       = {english},
  langidopts   = {variant=american},
  annotation   = {The Netflix data is not publicly available, but the GroupLens research lab109 
                  generated their own database with over 20 million ratings 
                  for over 27,000 movies by more than 138,000 users. 
                  We make a small subset of this data available via the dslabs package},
}

@book{IDS_E1_33-7-4,
  author       = {Rafael A. Irizarry},
  title        = {Introduction to Data Science, First Edition, Chapter 33: Large datasets, Section 33.7.4: A first model},
  date         = {2019-10-24},
  url          = {https://rafalab.dfci.harvard.edu/dsbook/large-datasets.html#a-first-model},
  subtitle     = {Data Analysis and Prediction Algorithms with R},
  urldate      = {2019-10-24},
  langid       = {english},
  langidopts   = {variant=american},
  annotation   = {Let’s start by building the simplest possible recommendation system: 
                  we predict the same rating for all movies regardless of user. 
                  What number should this prediction be? 
                  We can use a model based approach to answer this.},
}

@book{IDS_E1_33-7-6,
  author       = {Rafael A. Irizarry},
  title        = {Introduction to Data Science, First Edition, Chapter 33: Large datasets, Section 33.7.6: User Effects},
  date         = {2019-10-24},
  url          = {https://rafalab.dfci.harvard.edu/dsbook/large-datasets.html#user-effects},
  subtitle     = {Data Analysis and Prediction Algorithms with R},
  urldate      = {2019-10-24},
  langid       = {english},
  langidopts   = {variant=american},
  annotation   = {Let’s compute the average rating for user `u` for those that have rated 100 or more movies and see
                  that there is substantial variability across users as well: 
                  some users are very cranky and others love every movie.},
}

@book{IDS_E1_33-11,
  author       = {Rafael A. Irizarry},
  title        = {Introduction to Data Science, First Edition, Chapter 33: Large datasets, Section 33.11 Matrix factorization},
  date         = {2019-10-24},
  url          = {https://rafalab.dfci.harvard.edu/dsbook/large-datasets.html#matrix-factorization},
  subtitle     = {Data Analysis and Prediction Algorithms with R},
  urldate      = {2019-10-24},
  langid       = {english},
  langidopts   = {variant=american},
  annotation   = {Matrix factorization is a widely used concept in machine learning. 
                  It is very much related to factor analysis, singular value decomposition (SVD), 
                  and principal component analysis (PCA). 
                  Here we describe the concept in the context of movie recommendation systems.},
}

@book{IDS2,
  author       = {Rafael A. Irizarry},
  title        = {Introduction to Data Science, Part II},
  date         = {2024-12-27},
  url          = {https://rafalab.dfci.harvard.edu/dsbook-part-2/},
  subtitle     = {Statistics and Prediction Algorithms Through Case Studies},
  urldate      = {2025-02-18},
  langid       = {english},
  langidopts   = {variant=american},
  sorttitle    = {Introduction to Data Science, Part II},
  annotation   = {This book introduces concepts and skills that can help you tackle 
                  real-world data analysis challenges. 
                  It covers concepts from probability, statistical inference, 
                  linear regression and machine learning.},
}

@book{IDS2_17,
  author       = {Rafael A. Irizarry},
  title        = {Introduction to Data Science, Part II, Chapter 17: Treatment effect models},
  date         = {2024-12-27},
  url          = {https://rafalab.dfci.harvard.edu/dsbook-part-2/linear-models/treatment-effect-models.html},
  urldate      = {2025-02-18},
  langid       = {english},
  langidopts   = {variant=american},
  annotation   = {In this chapter, we consider an experiment designed to test for the effects 
                  of a high-fat diet on mouse physiology. Mice were randomly selected 
                  and divided into two groups: one group receiving a high-fat diet, considered the treatment, 
                  while the other group served as the control and received the usual chow diet. },
}

@book{IDS2_17-6,
  author       = {Rafael A. Irizarry},
  title        = {Introduction to Data Science, Part II, Chapter 17: Treatment effect models,  Section 17.6: Analysis of variance (ANOVA)},
  date         = {2024-10-27},
  url          = {https://rafalab.dfci.harvard.edu/dsbook-part-2/linear-models/treatment-effect-models.html#sec-anova},
  urldate      = {2025-10-27},
  langid       = {english},
  langidopts   = {variant=american},
  annotation   = {When a factor has more than one level, it is common to want to determine 
                  if there is significant variability across the levels rather 
                  than specific difference between any given pair of levels. 
                  Analysis of variances (ANOVA) provides tools to do this.},
}

@book{IDS2_24-1,
  author       = {Rafael A. Irizarry},
  title        = {Introduction to Data Science, Part II, Chapter 24: Regularization,  Section 24.1: Case study: recommendation systems},
  date         = {2025-10-27},
  url          = {https://rafalab.dfci.harvard.edu/dsbook-part-2/highdim/regularization.html#sec-recommendation-systems},
  subtitle     = {Statistics and Prediction Algorithms Through Case Studies},
  urldate      = {2025-10-27},
  langid       = {english},
  langidopts   = {variant=american},
  annotation   = {The Netflix data is not publicly available, but the GroupLens research lab2 
                  generated their own database with over 20 million ratings 
                  for over 27,000 movies by more than 138,000 users. 
                  We make a small subset of this data available via the dslabs package.},
}

@book{IDS2_24-1_LF,
  author       = {Rafael A. Irizarry},
  title        = {Introduction to Data Science, Part II, Chapter 24: Regularization,  Section 24.1: Case study: recommendation systems / Loss function},
  date         = {2025-10-27},
  url          = {https://rafalab.dfci.harvard.edu/dsbook-part-2/highdim/regularization.html#sec-netflix-loss-function},
  urldate      = {2025-10-27},
  langid       = {english},
  langidopts   = {variant=american},
  annotation   = {The Netflix challenge defined the winning entry as the one that minimized the root mean squared error (RMSE) on a test set.
                  We can interpret RMSE in the same units as the ratings themselves. It behaves much like a standard deviation: 
                  it represents the typical size of the error in our predictions. A value greater than 1 means that, on average, 
                  our predicted rating is off by more than one star, which is undesirable.},
}

@book{IDS2_24-1_UE,
  author       = {Rafael A. Irizarry},
  title        = {Introduction to Data Science, Part II, Chapter 24: Regularization,  Section 24.1: Case study: recommendation systems / User effects},
  date         = {2025-10-27},
  url          = {https://rafalab.dfci.harvard.edu/dsbook-part-2/highdim/regularization.html#user-effects},
  urldate      = {2025-10-27},
  langid       = {english},
  langidopts   = {variant=american},
  annotation   = {A natural question is whether all users rate movies in the same way. 
                  Some users tend to give very high ratings, while others rarely give more than three stars. 
                  To see this, we compute the average rating for each user.},
}

@book{IDS2_24-1_ME,
  author       = {Rafael A. Irizarry},
  title        = {Introduction to Data Science, Part II, Chapter 24: Regularization,  Section 24.1: Case study: recommendation systems / Movie effects},
  date         = {2025-10-27},
  url          = {https://rafalab.dfci.harvard.edu/dsbook-part-2/highdim/regularization.html#sec-movie-effects},
  urldate      = {2025-10-27},
  langid       = {english},
  langidopts   = {variant=american},
  annotation   = {Users differ in how they rate movies, but movies themselves also vary in how they are received. 
                  Some movies are widely liked, while others consistently receive low ratings. 
                  To capture this source of variation, we extend our model by adding a movie-specific effect.},
}

@book{IDS2_24-2,
  author       = {Rafael A. Irizarry},
  title        = {Introduction to Data Science, Part II, Chapter 24: Regularization,  Section 24.2: Penalized least squares},
  date         = {2025-10-27},
  url          = {https://rafalab.dfci.harvard.edu/dsbook-part-2/highdim/regularization.html#penalized-least-squares},
  urldate      = {2025-10-27},
  langid       = {english},
  langidopts   = {variant=american},
  annotation   = {In the previous section, we saw that the largest movie effect estimates came from movies with only one or two ratings. 
                  These estimates are unstable, and the resulting predictions can be highly inaccurate. 
                  This is a classic example of overfitting, in which estimates become too large because they rely on too little data.
                  A common way to address overfitting in linear models is to add a penalty that shrinks large coefficients toward zero. 
                  This approach is known as penalized least squares, or ridge regression when the penalty is quadratic.},
}

@book{IDS2_24-3,
  author       = {Rafael A. Irizarry},
  title        = {Introduction to Data Science, Part II, Chapter 24: Regularization,  Section 24.3: Selecting the penalty term},
  date         = {2025-10-27},
  url          = {https://rafalab.dfci.harvard.edu/dsbook-part-2/highdim/regularization.html#sec-selecting-penalty-term},
  urldate      = {2025-10-27},
  langid       = {english},
  langidopts   = {variant=american},
  annotation   = {The regularization parameter `lambda` controls how strongly we shrink the movie effects. 
                  If `lambda`is too small, we do not reduce overfitting. 
                  If it is too large, we shrink too much and lose useful signal.
                  In `Chapter 29`, we introduce formal methods for choosing tuning parameters. 
                  Here, we take a simple approach for illustrative purposes: we compute the RMSE for a range of `lambda`
                  values and pick the one that gives the best performance on our test set.},
}

@book{IDS2_24-4,
  author       = {Rafael A. Irizarry},
  title        = {Introduction to Data Science, Part II, Chapter 24: Regularization, Section 24.4: Exercises},
  date         = {2025-10-27},
  url          = {https://rafalab.dfci.harvard.edu/dsbook-part-2/highdim/regularization.html#exercises},
  subtitle     = {Statistics and Prediction Algorithms Through Case Studies},
  urldate      = {2025-10-27},
  langid       = {english},
  langidopts   = {variant=american}
}

@book{IDS2_29-6,
  author       = {Rafael A. Irizarry},
  title        = {Introduction to Data Science, Part II, Chapter 29: Resampling and Model Assessment, Section 29.6: Cross validation},
  date         = {2025-10-27},
  url          = {https://rafalab.dfci.harvard.edu/dsbook-part-2/ml/resampling-methods.html#cross-validation},
  urldate      = {2025-10-27},
  langid       = {english},
  langidopts   = {variant=american},
  annotation   = {Overall, we are provided a dataset and we need to build an algorithm, 
                  using this dataset, that will eventually be used in completely 
                  independent datasets that we might not even see.},
}

@book{IDS2_29-6_KFCV,
  author       = {Rafael A. Irizarry},
  title        = {Introduction to Data Science, Part II, Chapter 29: Resampling and Model Assessment, Section 29.6: Cross validation / K-fold cross validation},
  date         = {2025-10-27},
  url          = {https://rafalab.dfci.harvard.edu/dsbook-part-2/ml/resampling-methods.html#k-fold-cross-validation},
  urldate      = {2025-10-27},
  langid       = {english},
  langidopts   = {variant=american},
  annotation   = {We want to generate a dataset that can be thought of as independent random sample, and do this `B`times. 
                  The K in K-fold cross validation, represents the number of time `B`. 
                  In the illustrations below we show an example that uses `B = 5`.},
}


@book{IDS2_23-1-1,
  author       = {Rafael A. Irizarry},
  title        = {Introduction to Data Science, Part II, Chapter 25: Regularization,  Section 23.1.1: Movielens data},
  date         = {2024-12-27},
  url          = {https://rafalab.dfci.harvard.edu/dsbook-part-2/highdim/regularization.html#movielens-data},
  subtitle     = {Statistics and Prediction Algorithms Through Case Studies},
  urldate      = {2025-02-18},
  langid       = {english},
  langidopts   = {variant=american},
  annotation   = {The Netflix data is not publicly available, but the GroupLens research lab2 
                  generated their own database with over 20 million ratings 
                  for over 27,000 movies by more than 138,000 users. 
                  We make a small subset of this data available via the dslabs package.},
}

@book{IDS2_23-2,
  author       = {Rafael A. Irizarry},
  title        = {Introduction to Data Science, Part II, Chapter 25: Regularization, Section 23.2: Loss function},
  date         = {2024-12-27},
  url          = {https://rafalab.dfci.harvard.edu/dsbook-part-2/highdim/regularization.html#sec-netflix-loss-function},
  subtitle     = {Statistics and Prediction Algorithms Through Case Studies},
  urldate      = {2025-02-18},
  langid       = {english},
  langidopts   = {variant=american},
  annotation   = {The Netflix challenge decided on a winner 
                  based on the root mean squared error (RMSE) computed on the test set.},
}

@book{IDS2_23-3,
  author       = {Rafael A. Irizarry},
  title        = {Introduction to Data Science, Part II, Chapter 25: Regularization, Section 23.3: A first model},
  date         = {2024-12-27},
  url          = {https://rafalab.dfci.harvard.edu/dsbook-part-2/highdim/regularization.html#a-first-model},
  subtitle     = {Statistics and Prediction Algorithms Through Case Studies},
  urldate      = {2025-02-18},
  langid       = {english},
  langidopts   = {variant=american},
  annotation   = {A model that assumes the same rating for all movies and users 
                  with all the differences explained by random variation.},
}

@book{IDS2_23-4,
  author       = {Rafael A. Irizarry},
  title        = {Introduction to Data Science, Part II, Chapter 25: Regularization, Section 23.4: User effects},
  date         = {2024-12-27},
  url          = {https://rafalab.dfci.harvard.edu/dsbook-part-2/highdim/regularization.html#user-effects},
  subtitle     = {Statistics and Prediction Algorithms Through Case Studies},
  urldate      = {2025-02-18},
  langid       = {english},
  langidopts   = {variant=american},
  annotation   = {There is substantial variability across users: some users are 
                  very cranky and others love most movies. To account for this, 
                  we can use a linear model with a treatment effect for each user.},
}

@book{IDS2_24,
  author       = {Rafael A. Irizarry},
  title        = {Introduction to Data Science, Part II, Chapter 24: Matrix Factorization},
  date         = {2024-12-27},
  url          = {https://rafalab.dfci.harvard.edu/dsbook-part-2/highdim/matrix-factorization.html},
  subtitle     = {Factor analysis},
  urldate      = {2025-02-18},
  langid       = {english},
  langidopts   = {variant=american},
  annotation   = {In this chapter, we introduce Factor Analysis, an approach 
                  that permits us to model these correlations and improve our prediction, 
                  and the Singular Value Decomposition, which permits us to fit the model.},
}


@book{IDS2_29,
  author       = {Rafael A. Irizarry},
  title        = {Introduction to Data Science, Part II, Chapter 29: Resampling methods},
  date         = {2024-12-27},
  url          = {https://rafalab.dfci.harvard.edu/dsbook-part-2/ml/resampling-methods.html},
  urldate      = {2025-02-18},
  langid       = {english},
  langidopts   = {variant=american},
  annotation   = {In this chapter, we introduce resampling, one of the most important ideas in machine learning. 
                  Here we focus on the conceptual and mathematical aspects. 
                  We will describe how to implement resampling methods in practice 
                  with the caret package later in Section 31.1.3.},
}

@book{RRSK_RS_HB,
  author      = {Francesco Ricci},
  title       = {Recommender Systems Handbook},
  editor      = {Lior Rokach, Bracha Shapira, Paul B. Kantor},
  publisher   = {Springer, New York},
  year        = {2011},
  isbn        = {ISBN 978-0-387-85819-7},
  doi         = {10.1007/978-0-387-85820-3},
  langid      = {english},
  langidopts  = {variant=american},
  url         = {https://github.com/vwang0/recommender_system/blob/master/Recommender%20Systems%20Handbook.pdf},
  annotation  = {This is the first comprehensive book which is dedicated 
                 entirely to the field of recommender systems and covers several 
                 aspects of the major techniques},
}

@online{NYT1MNP,
  author       = {Steve Lohr},
  title        = {Netflix Awards \$1 Million Prize and Starts a New Contest},
  date         = {2009-09-21},
  year         = {2009},
  url          = {https://archive.nytimes.com/bits.blogs.nytimes.com/2009/09/21/netflix-awards-1-million-prize-and-starts-a-new-contest/index.html},
  subtitle     = {Adding details announced Monday about the extremely close finish to the contest},
  urldate      = {2025-02-18},
  langid       = {english},
  langidopts   = {variant=american},
  sorttitle    = {Netflix Awards \$1 Million Prize and Starts a New Contest},
  annotation   = {Netflix, the movie rental company, has decided its million-dollar-prize 
                  competition was such a good investment that it is planning another one},
}

@online{BigChaosSln,
  author       = {Andreas Toscher, Michael Jahrer, Robert M. Bell},
  title        = {The BigChaos Solution to the Netflix Grand Prize},
  date         = {2009-09-05},
  url          = {https://www.asc.ohio-state.edu/statistics/statgen/joul_aut2009/BigChaos.pdf},
  subtitle     = {commendo research \& consulting},
  urldate      = {2025-02-18},
  langid       = {english},
  langidopts   = {variant=american},
  sorttitle    = {The BigChaos Solution to the Netflix Grand Prize},
  annotation   = {The documentation of the Netflix Grand Prize consists of three parts. 
                  In this document we focus on the contribution of BigChaos 
                  to the combined Grand Prize Solution.},
}

@online{BelKor_Sln_NGP,
  author       = {Yehuda Koren},
  title        = {The BellKor Solution to the Netflix Grand Prize},
  date         = {2009-08-01},
  url          = {https://www2.seas.gwu.edu/~simhaweb/champalg/cf/papers/KorenBellKor2009.pdf},
  urldate      = {2025-02-18},
  langid       = {english},
  langidopts   = {variant=american},
  sorttitle    = {The BellKor Solution to the Netflix Grand Prize},
  annotation   = {This article describes part of our contribution to the “Bell-
                  Kor’s Pragmatic Chaos” final solution, which won the Netflix
                  Grand Prize.},
}

@online{MFT_RS,
  author       = {Yehuda Koren, Yahoo Research, Robert Bell and Chris Volinsky},
  title        = {Matrix Factorization Techniques for Recommender Systems},
  date         = {2009-08-01},
  url          = {https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf},
  urldate      = {2025-02-18},
  langid       = {english},
  langidopts   = {variant=american},
  sorttitle    = {Matrix Factorization Techniques for Recommender Systems},
  annotation   = {As the Netflix Prize competition has demonstrated,
                  matrix factorization models
                  are superior to classic nearest-neighbor
                  techniques for producing product recommendations,
                  allowing the incorporation
                  of additional information such as implicit
                  feedback, temporal effects, and confidence
                  levels.},
}

@online{MVRM_DL,
    author    = {Manisha Valera, Dr. Rahul Mehta},
    title     = {Advanced Deep Learning Models for Improving Movie Rating Predictions: A Benchmarking Study},
    date      = {2024-12-01},
    url       = {https://www.sciencedirect.com/science/article/pii/S2772485925000134#:~:text=In%20this%20work%2C%20the%20authors,capturing%20user%20preferences%20over%20time.},
    langid    = {english},
}

@online{IADS_4,
    author    = "The Pragmatic Editorial Team",
    title     = "The 4 Important Aspects of Data Science",
    url       = "https://www.pragmaticinstitute.com/resources/articles/data/4-important-aspects-of-data-science/",
    langid    = {english},
}

@online{markey,
  author       = {Markey, Nicolas},
  title        = {Tame the BeaST},
  date         = {2005-10-16},
  url          = {http://tug.ctan.org/tex-archive/info/bibtex/tamethebeast/ttb_en.pdf},
  subtitle     = {The B to X of BibTeX},
  version      = {1.3},
  urldate      = {2025-02-18},
  langid       = {english},
  langidopts   = {variant=american},
  sorttitle    = {Tame the Beast},
  annotation   = {An \texttt{online} entry for a tutorial. Note the format of
                  the \texttt{date} field (\texttt{yyyy-mm-dd}) in the database
                  file.},
}

@online{knuthwebsite,
    author    = "Donald Knuth",
    title     = "Knuth: Computers and Typesetting",
    url       = "http://www-cs-faculty.stanford.edu/~uno/abcde.html",
    keywords  = "latex,knuth"
}


@Manual{R-base,
  title = {R: A Language and Environment for Statistical
           Computing},
  author = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  address = {Vienna, Austria},
  year = {2019},
  url = {https://www.R-project.org},
}

@Book{ggplot2,
  author = {Hadley Wickham},
  title = {ggplot2: Elegant Graphics for Data Analysis},
  publisher = {Springer-Verlag New York},
  year = {2016},
  isbn = {978-3-319-24277-4},
  url = {http://ggplot2.org},
}