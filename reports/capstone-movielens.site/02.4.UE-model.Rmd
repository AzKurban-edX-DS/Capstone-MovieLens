## User Effect (UE) Model
\

### User Effect Anasysis
\

To improve our model let's now take into consideration user effects as explained in [Section 24.1 *Case study: recommendation systems / User effects*](https://rafalab.dfci.harvard.edu/dsbook-part-2/highdim/regularization.html#user-effects) of the *Course Textbook (New Edition)*.

If we visualize the average rating for each user the way the the author shows, we can see that there is substantial variability in the average ratings across users[@IDS2_24-1]: 
```{r}
hist(edx.user_mean_ratings$mean_rating,
     xlab = "User Average Rating",
     main = "Histogram of User Average Rating",
     nclass = 30)
```

\newpage

### Mathematical Description of the UE Model
\

Following the *Course Textbook* author's [further explanation](https://rafalab.dfci.harvard.edu/dsbook-part-2/highdim/regularization.html#user-effects), to account for this variability, we will use a linear model with a _treatment effect_  $\alpha_i$ for each user. The sum $\mu+\alpha_i$ can be interpreted as the typical rating user $i$ gives to movies. So we write the model as follows:

$$
Y_{i,j} = \mu + \alpha_i + \varepsilon_{i,j}
$$

Statistics textbooks refer to the $\alpha$s as treatment effects. In the Netflix challenge papers, they refer to them as _bias_[@IDS2_24-1; @MFT_RS].

### UE Model Building
\

::: {.noteblock data-latex=""}
The complete source code of the _User Effect_ computation described in this section is available in the [User Effect (UE) Model](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R#L210) section of the [capstone-movielens.main.R](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R#L210) script on _GitHub_.
:::

As it is stated in the [Course Textbook](https://rafalab.dfci.harvard.edu/dsbook-part-2/highdim/regularization.html#user-effects), it can be shown that the least squares estimate $\hat{\alpha}_i$ is just the average of $y_{i,j} - \hat{\mu}$ for each user $i$. So we can compute them this way[@IDS2_24-1]:
```{r eval=FALSE}
a <- rowMeans(y - mu, na.rm = TRUE)
```

These considerations alows us to compute a _User Mean Ratings_ the following way:
```{r eval=FALSE}
put_log("Computing Average Ratings per User (User Mean Ratings)...")
user.mean_ratings <- rowMeans(edx.mx, na.rm = TRUE)
user_ratings.n <- rowSums(!is.na(edx.mx))
  
edx.user_mean_ratings <- 
  data.frame(userId = names(user.mean_ratings), 
             mean_rating = user.mean_ratings,
             n = user_ratings.n)
  
put_log("User Mean Ratings have been computed.")
```
```{r}
str(edx.user_mean_ratings)
```

And then we compute a _User Effect_ this way:
```{r eval=FALSE}
put_log("Computing User Effect per users ...")
edx.user_effect <- edx.user_mean_ratings |>
  mutate(userId = as.integer(userId),
         a = mean_rating - mu)

put_log("A User Effect Model has been builded")
```
```{r}
par(cex = 0.7)
hist(edx.user_effect$a, 30, xlab = TeX(r'[$\hat{alpha}_{i}$]'),
     main = TeX(r'[Histogram of $\hat{alpha}_{i}$]'))

str(edx.user_effect)
```

Now, we are ready to compute the _Mean Squared Errors_ for samples used in _K-Fold Cross-Validation_ (additionally using the [clamp](#func.clamp) helper function (described in the [Utility Functions] section of [Appendix A](#appndx_a)).

::: {.noteblock data-latex=""}
The `K` value for the *K-Fold Cross-Validation* method is determined by the length of the [`edx_CV` Object] described below in the [Appendix B: Models Training Datasets] (in *this Project* we use `K = 5`).
:::

The code that performs this operation is shown below:
```{r eval=FALSE}
put_log("Computing the RMSE taking into account user effects...")
edx.user_effect.MSEs <- sapply(edx_CV, function(cv_fold_dat){
  cv_fold_dat$validation_set |>
    left_join(edx.user_effect, by = "userId") |>
    mutate(resid = rating - clamp(mu + a)) |> 
    pull(resid) |> mse()
})
```
```{r}
data.frame(fold_No = 1:5, MSE = edx.user_effect.MSEs) |>
  data.plot(title = "MSE resuls of the 5-fold CV method applied to the User Effect Model",
            xname = "fold_No", 
            yname = "MSE")

```

::: {.noteblock data-latex=""}
For the _Mean Squared Errors_ data visualization we use the custom data visualization function [data.plot](#func.data.plot) described in the [Data Visualization Functions](#appndx_a.data_helper.functions) section of [Appendix A](#appndx_a).
:::

Finally, we calculate the `RMSE` as the _square root_ of the average of the _Mean Squared Errors_ we obtained through the _5-Fold Cross-Validation_ above:   
```{r, eval=FALSE}
edx.user_effect.RMSE <- sqrt(mean(edx.user_effect.MSEs))

RMSEs.ResultTibble.UE <- RMSEs.ResultTibble.OMR |> 
  RMSEs.AddRow("User Effect Model", edx.user_effect.RMSE)
```
```{r}
RMSE_kable(RMSEs.ResultTibble.UE)
```

::: {.noteblock data-latex=""}
To print the table above, we use the [RMSEs.AddRow](#func.RMSEs.AddRow) and [RMSE_kable](#func.RMSE_kable) functions described in the [Result RMSEs Tibble Functions] section of [Appendix A](#appndx_a).
:::

\newpage
