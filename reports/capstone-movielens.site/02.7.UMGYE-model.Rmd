## User+Movie+Genre+Year Effect (UMGYE) Model
\

### Year Effect Analysis

::: {.noteblock data-latex=""}
The _Year Effect_ visualization and analysis code in this section are cited from the article [Movie Recommendation System using R - BEST](https://www.kaggle.com/code/amirmotefaker/movie-recommendation-system-using-r-best/notebook) mentioned earlier in this report[@MRS-R-BEST].
:::

#### Yearly rating count[@MRS-R-BEST]
\
```{r}
print(edx |> 
  mutate(year = year(as_datetime(timestamp, origin = "1970-01-01"))) |>
  group_by(year) |>
  summarize(count = n())
)
```

#### Average rating per year plot[@MRS-R-BEST]
\
```{r}
edx |> 
  mutate(year = year(as_datetime(timestamp, origin = "1970-01-01"))) |>
  group_by(year) |>
  summarize(rating_avg = mean(rating)) |>
  ggplot(aes(x = year, y = rating_avg)) +
  geom_bar(stat = "identity", fill = "#8888ff") + 
  ggtitle("Average rating per year") +
  xlab("Year") +
  ylab("Average rating") +
  scale_y_continuous(labels = comma) + 
  theme_economist() +
  theme(axis.title.x = element_text(vjust = -5, face = "bold"), 
        axis.title.y = element_text(vjust = 10, face = "bold"), 
        plot.margin = margin(0.7, 0.5, 1, 1.2, "cm"))
```

\newpage

### Mathematical Description of the UMGYE Model
\

If we define $\gamma(v_{i,j})$ as the _year effect_ for the year (here denotes by $v_{i,j}$) of rating a movie $j$ by a user $i$, the formula \@ref(eq:UMGE-model) describing the _UMGE Model_, for the current model, takes the form:

\begin{equation}
Y_{i,j} = \mu + \alpha_i + \beta_j + g_{i,j} + \gamma(v_{i,j}) + \varepsilon_{i,j}
(\#eq:UMGYE-model)
\end{equation}

Therefore, the formula \@ref(eq:genre-effect) for calculation the prediction of a _genre effect_ as a residual, for a _year effect_ 
$$
\hat{\gamma}(v_{i,j}) = \gamma(v_{i,j}) + \varepsilon_{i,j}
$$

takes the following form: 

\begin{equation}
\hat{\gamma}(v_{i,j}) = Y_{i,j} - (\mu + \alpha_i + \beta_j + g_{i,j})
(\#eq:year-effect)
\end{equation}

\newpage

### UMGYE Model Building
\

::: {.noteblock data-latex=""}
The complete source code of building and training the current model is available in the [UMGYE Model Building](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R#L1163) section of the [capstone-movielens.main.R](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R#L1163) script on _GitHub_.
:::

Below, we provide the [line of code](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R#L1177) for training our model using the *K-Fold Cross Validation* method, where the $K$ is the length of the [`edx_CV` Object] (described in detail in [Appendix B: Models Training Datasets]) to which the *K-Fold Cross-Validation* is applied (in *this Project* we use $K = 5$):
```{r  main-script@l1177, eval=FALSE}
  cv.UMGY_effect <- train_UMGY_effect.cv()
```
```{r}
str(cv.UMGY_effect)
summary(cv.UMGY_effect)
```


We can now validate the current model by computing the *RMSE* for the *UMGY* Effect using the following [line of code](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R#L1195): 
```{r  main-script@l1195, eval=FALSE}
cv.UMGY_effect.RMSE <- calc_UMGY_effect_RMSE.cv(cv.UMGY_effect)

```

::: {.noteblock data-latex=""}
In the code snippets above, we use the [train_UMGY_effect.cv](#func.train_UMGY_effect.cv) and [calc_UMGY_effect_RMSE.cv](#func.calc_UMGY_effect_RMSE.cv) functions described in the [UMGYE Model: Utility Functions] section of [Appendix A](#appndx_a) to *this Report*.
:::


```{r, eval=FALSE}
RMSEs.ResultTibble.UMGYE <- RMSEs.ResultTibble.rglr.UMGE |> 
  RMSEs.AddRow("UMGYE Model", 
               cv.UMGY_effect.RMSE,
               comment = "User+Movie+Genre+Year Effect (UMGYE) Model")
```
```{r}
RMSE_kable(RMSEs.ResultTibble.UMGYE)
```

::: {.noteblock data-latex=""}
In the code snippets above, we use the [RMSEs.AddRow](#func.RMSEs.AddRow) and [RMSE_kable](#func.RMSE_kable) functions described in the [Result RMSEs Tibble Functions] section of [Appendix A](#appndx_a).
:::

Now, we have a bit better result than one for the previous (*Regularized UMGE*) model.

\newpage

### UMGYE Model Regularization
\

::: {.noteblock data-latex=""}
The complete version of the source code provided in this section can be found in the [UMGYE Model Regularization](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R#L1210) section of the [capstone-movielens.main.R](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R#L1210) script.
:::

#### UMGYE Model Regularization: Mathematical Description
\

We have already explained the idea of _Linear Model Regularization_ in the [UME Model Regularization] section above. We have also seen how the formula \@ref(eq:ME-penalty) for adding a penalty to the _UME Model_ is transformed into the formula \@ref(eq:GE-penalty) for the _UMGE Model_. For the current model, this formula takes the form:

\begin{equation}
\sum_{i,j} \left(y_{u,i} - \mu - \alpha_i - \beta_j - g_{i,j} - \gamma(v_{i,j})\right)^2 + \lambda \sum_{i,j} \gamma(v_{i,j})^2
(\#eq:YE-penalty)
\end{equation}

And the formula \@ref(eq:GE-regularized) for calculating the values of the _treatment effect_ that minimizes the equation will take the form:

\begin{equation}
\hat{\gamma}(v_{i,j}, \lambda) = \frac{1}{\lambda + n_v} \sum_{r=1}^{n_v} \left(Y_{i,j} - \mu - \alpha_i - \beta_j - g_{i,j}\right)
(\#eq:YE-regularized)
\end{equation}

where $n_v$ is the number of ratings made in year $v$. 

As with the previous models, we implement the _Regularization_ method for the current model in the following three steps:

  1. **Pre-configuration:** Preliminary determination of the optimal range of $\lambda$ values for the *K-Fold Cross Validation* samples, where the $K$ is the length of the [`edx_CV` Object] (described in detail in [Appendix B: Models Training Datasets]) to which the *K-Fold Cross-Validation* is applied (in *this Project* we use $K = 5$);
  
  2. **Fine-tuning:** figuring out the value of $\lambda$ that minimizes the model's RMSE.
  
  3. **Retraining:** retraining the model with the best value of the parameter $\lambda$ obtained in the previous step.


\newpage

#### UMGYE Model Regularization: Pre-configuration
\

::: {.noteblock data-latex=""}
The complete version of the source code provided in this section can be found in the [UMGYE Model Regularization: Pre-configuration](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R#L1224) section of the [capstone-movielens.main.R](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R#L1224) script on _GitHub_.
:::

As for previous models, we will use the function [tune.model_param](#func.tune.model_param) passing in the [fn_tune.test.param_value](#func.tune.model_param.args.fn_tune.test.param_value) argument the model-specific helper function (this time designed for the *UMGYE Model*): [regularize.test_lambda.UMGY_effect.cv](#func.regularize.test_lambda.UMGY_effect.cv).

::: {.noteblock data-latex=""}
The functions [tune.model_param](#func.tune.model_param) and [regularize.test_lambda.UMGY_effect.cv](#func.regularize.test_lambda.UMGY_effect.cv) are described in the sections [Common Helper Functions]/[Model Tuning Utils](#appndx_a.CHF.model_tuning_utils) and  [Models Training: Support Functions]/[UMGYE Model: Regularization], respectively, of [Appendix A: Support Functions].
:::

The following [piece of code](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R#L1241) performs this operation:
```{r  main-script@l1241, eval=FALSE}
  lambdas <- seq(0, 512, 32)
  cv.UMGYE.preset.result <- 
    tune.model_param(lambdas, 
                     regularize.test_lambda.UMGY_effect.cv,
                     steps.beyond_min = 16)
```
```{r}
str(cv.UMGYE.preset.result)
cv.UMGYE.preset.result$best_result
```

Now, let's visualize the results of the $\lambda$ range pre-configuration:
``` {r}
cv.UMGYE.preset.result$tuned.result |>
  data.plot(title = TeX(r'[UMGYE Model Regularization: $\lambda$ Range Pre-configuration]'),
              xname = "parameter.value", 
              yname = "RMSE", 
              xlabel = TeX(r'[$\lambda$]'), 
              ylabel = "RMSE")
```

::: {.noteblock data-latex=""}
In the code snippet above, we use the custom data visualization function [data.plot](#func.data.plot) described in the [Data Helper Functions]/[Data Visualization Functions] section of [Appendix A](#appndx_a).
:::

\newpage

#### UMGYE Model Regularization: Fine-tuning
\

::: {.noteblock data-latex=""}
The complete version of the source code provided in this section can be found in the [UMGYE Model Regularization: Fine-tuning](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R#L1281) section of the [capstone-movielens.main.R](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R#L1281) script on _GitHub_.
:::

We are now ready to perform the fine-tuning step of our model _regularization_ process to determine the best value for the $\lambda$ parameter.

The following [code snippet](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R#L1282) prepares the interval of values for the $\lambda$ parameter, over which the operation has to be done:
```{r, eval=FALSE}
endpoints <- 
  get_fine_tune.param.endpoints(cv.UMGYE.preset.result$tuned.result)

UMGYE.loop_starter <- c(endpoints["start"], 
                        endpoints["end"], 
                        8)
```
```{r, echo=FALSE}
writeLines("*** Values of the endpoints and the divisor for the interval of `lambda` values ***")
```
```{r}
UMGYE.loop_starter
```

::: {.noteblock data-latex=""}
The helper function [get_fine_tune.param.endpoints](#func.get_fine_tune.param.endpoints) used in code snippet above is described in the sections [Common Helper Functions]/[Model Tuning Utils](#appndx_a.CHF.model_tuning_utils) of [Appendix A: Support Functions].
:::

And the next [piece of code](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R#L1291) below accomplishes the task of *fine-tuning* the model:
```{r, eval=FALSE}
cache.base_name <- "UMGYE.rglr.fine-tuning"

UMGYE.rglr.fine_tune.results <- 
  model.tune.param_range(UMGYE.loop_starter,
                         UMGYE.rglr.fine_tune.cache.path,
                         cache.base_name,
                         regularize.test_lambda.UMGY_effect.cv)

UMGYE.rglr.fine_tune.RMSE.best <- UMGYE.rglr.fine_tune.results$best_result["best_RMSE"]
```

::: {.noteblock data-latex=""}
The custom functions [model.tune.param_range](#func.model.tune.param_range) and [regularize.test_lambda.UMGY_effect.cv](#func.regularize.test_lambda.UMGY_effect.cv) used in the code snippet above are described in the sections [Common Helper Functions]/[Model Tuning Utils](#appndx_a.CHF.model_tuning_utils) and  [Models Training: Support Functions]/[UMGYE Model: Regularization], respectively, of [Appendix A: Support Functions].
:::

Below are the results of fine-tuning the *UMGYE Model*:

```{r, echo=FALSE}
writeLines("*** Path to the cache directory for intermediate fine-tuning results ***")
```
```{r}
UMGYE.rglr.fine_tune.cache.path
```
```{r, echo=FALSE}
writeLines("*** Fine-tuning results object data structure ***")
```
```{r}
str(UMGYE.rglr.fine_tune.results)
```
```{r, echo=FALSE}
writeLines("*** Fine-tuning: best results ***")
```
```{r}
UMGYE.rglr.fine_tune.results$best_result
UMGYE.rglr.fine_tune.RMSE.best
```

\newpage

Let's visualize the fine-tuning results:
```{r}
UMGYE.rglr.fine_tune.results$tuned.result |>
  data.plot(title = "UMGYE Model Regularization: Fine-tuned result",
              xname = "parameter.value",
              yname = "RMSE",
              xlabel = TeX(r'[$\lambda$]'),
              ylabel = str_glue("Deviation from the best RMSE value (",
                                as.character(round(UMGYE.rglr.fine_tune.RMSE.best, digits = 7)),
                                ")"),
              normalize = TRUE)
```

::: {.noteblock data-latex=""}
Note that in the code snippet above, we use the custom data visualization function [data.plot](#func.data.plot) (described in the [Data Helper Functions]/[Data Visualization Functions] section of [Appendix A](#appndx_a)) with the argument [normalize](#func.data.plot.args.normalize) set to `TRUE`, which means that deviations from the minimum $y$ value are used to plot, rather than the $y$ values themselves.
:::

\newpage

#### UMGYE Model Regularization: Retraining the Model with the best $\lambda$
\

::: {.noteblock data-latex=""}
The complete version of the source code provided in this section are available in the [UMGYE Model Regularization: Re-training with the best `lambda`](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R#L1320) section of the [capstone-movielens.main.R](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R#L1320) script on _GitHub_.
:::

Now, we can refine our *User+Movie+Genre+Year Effect (UMGYE) Model* by retraining on the entire `edx` dataset with the best value of the $\lambda$ parameter we just figured out (let's call it *Regularized User+Movie+Genre+Year Effect Model* or *Regularized UMGYE Model* for short), for the definitive *RMSE* calculation and use in subsequent models.

The following [piece of code](https://github.com/AzKurban-edX-DS/Capstone-MovieLens/blob/main/r/src/capstone-movielens.main.R#L1333) performs this operation:
```{r, eval=FALSE}
best_result <- UMGYE.rglr.fine_tune.results$best_result
UMGYE.rglr.best_lambda <- best_result["param.best_value"]

put_log1("Re-training Regularized User+Movie+Genre+Year Effect Model for the best `lambda`: %1...",
         UMGYE.rglr.best_lambda)

rglr.UMGY_effect <- edx |> train_UMGY_effect(UMGYE.rglr.best_lambda)
```

::: {.noteblock data-latex=""}
In the code snippet above we use the [train_UMGY_effect](#func.train_UMGY_effect) function described in the [Models Training: Support Functions]/[UMGYE Model: Utility Functions] section of [Appendix A](#appndx_a).
:::

```{r, echo=FALSE}
writeLines("*** The Best UMGY Effect Fine-tuning Results ***")
```
```{r}
UMGYE.rglr.fine_tune.results$best_result
```

```{r, echo=FALSE}
writeLines("*** Regularized UMGY Effect Structure ***")
```
```{r}
str(rglr.UMGY_effect)

print_log1("Regularized UMGYE Model has been re-trained for the best `lambda`: %1.",
         UMGYE.rglr.best_lambda)
```

Finally, we calculate the *RMSE* for the ultimately *Regularized UMGYE Model* and add the definitive result to our *Result Table*:
```{r, eval=FALSE}
  rglr.UMGY_effect.RMSE <- calc_UMGY_effect_RMSE.cv(rglr.UMGY_effect)
```
```{r}
print_log1("The best RMSE for the UMGYE Model after being regularized: %1",
         rglr.UMGY_effect.RMSE)
```
```{r, eval=FALSE}
RMSEs.ResultTibble.rglr.UMGYE <- RMSEs.ResultTibble.UMGYE |> 
  RMSEs.AddRow("Regularized UMGYE Model", 
               rglr.UMGY_effect.RMSE,
               comment = "Computed for `lambda` = %1" |>
                 msg.glue(UMGYE.rglr.best_lambda))
```
```{r}
RMSE_kable(RMSEs.ResultTibble.rglr.UMGYE)
```

::: {.noteblock data-latex=""}
In the code snippet above, we use the following functions described in [Appendix A: Support Functions]: 

  - [calc_UMGY_effect_RMSE.cv](#func.calc_UMGY_effect_RMSE.cv) (described in the [Models Training: Support Functions]/[UMGYE Model: Utility Functions] section) to calculate the *RMSE* for the *UMGYE Model*;
  
  - [RMSEs.AddRow](#func.RMSEs.AddRow) and [RMSE_kable](#func.RMSE_kable) (described in the [Common Helper Functions]/[Result RMSEs Tibble Functions] section) to update and print the table above.
:::

\newpage

